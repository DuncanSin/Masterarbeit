
\section{Optimierung des ARM}
In diesem Kapitel werden die Optimierungen am Code beschrieben, der rein auf dem ARM Cortex-A8 ausgeführt wird. Hierfür werden die in \textbf{Kapitel \ref{subsec:a8}} beschriebenen Hardwareemelemte ausgenutzt.\\
In \textbf{Abschnitt \ref{subsec:armtime}} wird daher als erstes die Laufzeitmessung des gesamten Programms (Extraktion, Prozessierung und Klassifikation) erläutert, um einen Einstiegspunkt für die Optimierung zu extrahieren. In den darauffolgenden Abschnitten werden daraufhin die durchgeführten Optimierungen beschrieben. 

\subsection{Laufzeitmessung des Gesamtprogramms}\label{subsec:armtime}
Für die erste Laufzeitmessung des gesammten Programms (Extraktion, Prozessierung und Klassifikation) wurde dieses mit den in \textbf{Kapitel \ref{ph:neoncomp}} beschriebenen Compileroptionen zur automatischen Generierung von NEON-Code kompiliert. Die dabei resultierten Laufzeiten sind in \textbf{Abbildung \ref{fig:mclneon}} abzulesen.
%
\begin{figure}[htp]
	\centering
		\includegraphics[width=1\textwidth]{../Pictures/mclneon.pdf}
	\caption{Laufzeiten in ms des Musikklassifikators}
	\label{fig:mclneon}
\end{figure} 
%
Wie man aus der Abbildung entnehmen kann, fällt der größte Anteil an der Gesamtlaufzeit in allen vier Messungen (\textit{MCL1 - MCL4}) auf die Extraktionsphase. Hierbei stellt sich jetzt allerdings die Frage, ob das nur an der Komibation aus ARM und NEON liegt oder ob dieses eine generelle Tendenz ist. Darum muss die Laufzeitmessung der genannten Komibation noch mit den Laufzeitmessungen von einer reinen ARM-Implementation und der Kombination aus ARM und VFP-Einheit (vgl. \textbf{Kapitel \ref{ph:vfp}}) verglichen werden. Die Ergebnisse dieser sind in \textbf{Abbildung \ref{fig:armtime}} abzulesen. Diese und alle weiteren Messungen werden am Beispiel des in \textbf{Kapitel \ref{subsec:fset2}} beschriebenen FeatureSets durchgeführt, die Diagramme für die anderen drei FeatureSets sind für den interessierten Leser im Anhang zu finden, aber für diese sind die beschriebenen Tatsachen equivalent.
%
\begin{figure}[h]
	\centering
		\includegraphics[width=1\textwidth]{../Pictures/fset2AVN.pdf}
	\caption{Laufzeiten in ms des Musikklassifikators für ARM, ARM+VFP und ARM+NEON am Beispiel des FeatureSets 2}
	\label{fig:armtime}
\end{figure} 
%
Aus \textbf{Abbildung \ref{fig:armtime}} lassen sich drei wesentliche Schlüsse ziehen:

\begin{enumerate}
\item Die Extraktionsphase hat in allen drei Fällen den größten Anteil an der Laufzeit
\item Die reine ARM-Implementation hat die schlechteste Laufzeit
\item ARM+VFP und ARM+NEON scheinen gleichwertig zu sein
\end{enumerate}

Die Punkte 1 und 2 kann man so stehen lassen, da diese zu den erwarteten Ergebnissen zählen, aber Punkt 3 verwundert einen doch sehr. Wie kann es sein, dass trotz der in \textbf{Kapitel \ref{subsubsec:neon}} beschriebenen Vorteile der NEON-SIMD-Einheit gegen über der VFP-Einheit, beide Einheiten doch gleichwertig erscheinen? Es soll nochmals erwähnt werden, dass beide Implementationen mit einer Compileroption für die jeweilige Floating Point-Einheit optimiert wurden. Ein Blick in den entstandenen Assemblercode der beiden Implementierungen gibt die Antwort auf die gestellte Frage. Hier finden sich in beiden Fällen nahezu gleiche Codes, das heißt auch die NEON-SIMD-Einheit für nur die rein sklaren Operationen des VFP aus. Dieses erklärt einerseits, warum sich die Laufzeiten der beiden Implementationen nicht wesentlich voneinander unterscheiden und zeigt andererseits, dass es dem Compiler scheinbar nicht möglich ist effektiv für die NEON-SIMD-Einheit optimierten Code zu generieren.\\\\
Da die Extraktionsphase sich als am zeitintensivsten herausgestellt hat, soll diese jetzt näher analysiert werden.\\ 
Wie aus \textbf{Abbildung \ref{fig:1fset2}} zu entnehmen ist, fallt der größte Anteil der Laufzeit der Extraktionsphase mit knapp 60\% auf die Berechnung der FFT.
%
\begin{figure}[h]
	\centering
		\includegraphics[width=1\textwidth]{../Pictures/1fset2.pdf}
	\caption{Detailliertere Laufzeitmessung der Extraktionsphase}
	\label{fig:1fset2}
\end{figure} 
%
Nachdem die FFT als größter Bottleneck identifiziert wurde, stellt sich die Frage welcher Teil der Berechnung die meiste Zeit einnimmt. Wie in \textbf{Kapitel \ref{subsubsec:fft}} beschrieben, besteht die FFT-Berechnung aus drei Teilen:

\begin{itemize}
\item Bitreverse
\item Butterfly
\item Nachverarbeitung
\end{itemize}  

Eine Analyse dieser drei Teilberechnungen ergibt, dass der größte Anteil an der Laufzeit der Butterfly-Berechnung zufällt, in Zahlen liegt dieser bei knapp 72\%.

\subsection{Libav als Optimierung der FFT}\label{subsec:optFFT}

Im vorherigen Kapitel haben sich folgende Ergebnisse gezeigt:

\begin{enumerate}
\item ARM+NEON ist die schnellste Kombination
\item Die Extraktionsphase nimmt den größten Anteil der Gesamtlaufzeit ein
\item Die FFT nimmt den größten Anteil an der Laufzeit der Extraktionsphase ein
\item Innerhalb der FFT nimmt die Butterfly-Berechnung den größten Anteil ein
\end{enumerate}

Daraus folgt, dass eine erste Optimierung in Richtung der FFT und der NEON-SIMD-Einheit erfolgen sollte.\\
Bibliotheken, die NEON optimierte FFT-Versionen bieten, sind im Internet reichlich vertreten. Für diese Arbeit wurde sich dafür entschieden die weitverbreiteste Bibliothek \textit{Libav} einzusetzen.\\
Libav ist eine opensource Bibliothek zur Audio- und Videoverarbeitung, die neben einer Vielzahl von Audio- und Videocodecs, Prozessierungsalgorithmen für diese und Tools zur Audio- und Videoverarbeitung auch wie schon erwähnt eine NEON optimierte FFT besitzt.
 
\subsubsection{Laufzeitmessung}
Da der Aufbau der FFT-Berechnung (siehe \textbf{Kapitel \ref{subsubsec:libavfft}}) der Libav-Bibliothek an anderer ist, als der der Referenzimplementierung, wäre ein direkter Laufzeitvergleich zwischen Libav-FFT und Referenz-FFT unfair. Hier für wurden die Messungen der drei Kombinationen aus \textbf{Abbildung \ref{fig:armtime}} für die Libav-FFT wiederholt (vgl. \textbf{Abbildung \ref{fig:libavtime}}).
%
\begin{figure}[h]
	\centering
		\includegraphics[width=1\textwidth]{../Pictures/libavtime.pdf}
	\caption{Laufzeitmessung der Libav-FFT für ARM, ARM+VFP und ARM+NEON}
	\label{fig:libavtime}
\end{figure} 
%
Auch hierbei lässt sich erkennen, dass eine reine ARM-Implementation die langsamste Variante ist. Allerdings lässt sich ebenfalls erkennen, dass der Unterschied von der VFP-Implementierung und der NEON-Implementierung sehr deutlich ist, so wie es zu erwarten war. Dass dieser Unterschied hier so deutlich ist, liegt vor allem daran, dass die NEON-Version nicht wie bei der FFT des Referenzcodes mit der Compileroption für NEON-Code erstellt wurde, sondern wie in \textbf{Kapitel \ref{ph:neonasm}} beschrieben per Hand in NEON-Assembler geschrieben wurde.\\Im Vergleich zur Referenzimplementierung lässt sich für die reine ARM-Implementierung ein Speedup von knapp 1,4, für die VFP-Implementierung von 2,2 und für die NEON-Implementierung sogar von 19,2 erkennen. Bei der ARM-Implementierung ist dieses aus der geringeren Komplexität der Libav-FFT erklären, bei den andern Beiden kommt noch eine bessere Ausnutzung der Architektur hinzu.

\subsubsection{Aufbau der FFT}\label{subsubsec:libavfft}
Wie im vorherigen Kapitel schon erwähnt, unterscheiden sich der Aufbau von Libav-FFT und FFT des Referenzcodes stark, was unter anderem eine Komplexitätsreduktion der Butterfly-Berechnung und damit eine geringere Laufzeit mit sich bringt. In diesem Abschnitt wird nun dieser Unterschiedliche Aufbau näher erläutert.\\
Die FFT des Referenzcodes basiert auf den in \textbf{Kapitel \ref{subsubsec:fft}} beschriebenen Reduktionen einer 256-Punkt-FFT auf kleinere FFTs des Radix 2 Der Aufbau der Libav-FFT hingegen basiert auf der Reduktion auf Splitradix-FFTs. Beide FFTs basieren auf dem DIT-Prinzip (vgl. \textbf{Kapitel \ref{ph:dit}}).


\subsubsection{Einbindung}
Die Einbindung der Libav-FFT in den bestehenden FFT-Code ist schier einfach. Eigentlich muss nur die Referenzimplementierung der FFT durch den Aufruf der Libav-FFT ersetzt werden. Hinzu kommt eine Umdefinieren des verwendeten Vektors \textit{source}. Dieser wird um einen benutzerdefinierten  erweitert, der sicher stellt, dass die enthaltenen Werte alle mit 16 bit allokiert sind. Die Definition dieses Allokators ist in \cite{libavtemp} zu finden. Nach der Berechnung der FFT muss abschließend noch eine Auftrennung des resultierenden Vektors in Real- und Imaginärteil geschehen, da das Ergebnis der Libav einen Vektor darstellt, der abwechselt den Real- und Imaginärteil der Ergebnisse enthält.

\subsubsection{Laufzeitmessung nach der FFT-Optimierung mit Libav}

Nach der Optimierung des Bottlenecks FFT wird eine weitere Laufzeitmessung durchgeführt, um nachzuvollziehen, ob dieser Bottleneck verwunden und eventuell neue Bottlenecks aufgetaucht sind. Diese Messung ist in \textbf{Abbildung \ref{fig:postlibav}} zu finden.
%
\begin{figure}[h]
	\centering
		\includegraphics[width=1\textwidth]{../Pictures/postlibav.pdf}
	\caption{Laufzeitmessung nach der FFT-Optimierung}
	\label{fig:postlibav}
\end{figure} 
%
Wie man in \textbf{Abbildung \ref{fig:postlibav}} sieht, ergeben sich nach dieser Optimierung vier Algorithmen die langsamer sind als die neue FFT, hinzu kommt noch ein weiterer Algorithmus aus FeatureSet 3:

\begin{itemize}
\item Octave Spectral Contrast (siehe \textbf{Kapitel \ref{sec:vista}})
\item Magnitude of Sprectrum (\textbf{\ref{subsec:optAOS}})
\item MFCC (\textbf{\ref{subsec:optMFCC}})
\item Hamming Window (\textbf{\ref{subsec:optHAM}})
\item Zero Crossing Rate (\textbf{\ref{subsec:optZCR}})
\end{itemize}

Auf die Optimierung von OSC wird im Rahmen dieser Arbeit verzichtet, da 76\% der Laufzeit dieses Features auf die Sortierung fallen. Eine NEON-SIMD-Umsetzung dieser Sortierung würde den Rahmen dieser Arbeit sprengen.


\subsection{Optimierung der Magnitude of Spectrum}\label{subsec:optAOS}

Für die Optimierung der Magnitude of Spectrum wird auf die in \textbf{Kapitel \ref{ph:neonc}} beschriebene Taktik der Codeanpassung zurückgegriffen. Diese Codeanpassung soll es dem Compiler erleichtern stellen zu erkennen, die mit der NEON-SIMD-Einheit parallel berechnet werden können.\\
Hierfür müssen als erstes die Codestellen identifiziert werden, die es dem Compiler nicht ermöglichen eine Einbindmöglichkeit der NEON-SIMD-Einheit festzustellen. Ein Blick in den Instruktionssatz der NEON-SIMD-Einheit ermöglicht es die Wurzelberechnung als eine solche Problemstelle zu identifizieren. Dieses begründet sich auf die Tatsache, dass die NEON-SIMD-Einheit keine Befehle für die Berechnung einer Wurzel besitzt. Da sich die Division beschleunigen ließe, diese aber erst nach der Wurzelberechnung angewandt wird (vgl. \textbf{Formel \ref{eqn:aos}}), wird diese auf mathematischem Weg in die Wurzel gezogen. \textbf{Listing \ref{code:aosc}} zeigt den geänderten C-Code und \textbf{Listing \ref{code:aosasm}} den daraus resultierenden Assemblercode.

\begin{lstlisting}[caption=Codeanpassung der Magnitude of Spectrum, label=code:aosc]
	realv tmp, size2;

	size2 = (realv) size * size;
	for (int k = 0; k < size; k++) {
		tmp = fftX[k] * fftX[k] + fftY[k] * fftY[k];

		temp[k] = tmp / size2;

	}
	for (int k = 0; k < size; k++) {
		amplitude[k] = sqrt(temp[k]);
	}
\end{lstlisting}
Aus den beiden Listings lässt sich erkennen, dass sowohl die Zeile 5 aus \textbf{Listing \ref{code:aosc}} als auch die Division mit der NEON-SIMD-Einheit parallelisiert wurden, was eine kürzere Ausführungszeit bewirkt.
\newpage

\begin{lstlisting}[caption=Resultierender Assemblercode, label=code:aosasm]
	add	r2, r7, r1
	add	r3, r6, r1
	vld1.32	{d16}, [r2]       ;laden aus fftX;
	add	r0, r0, #1
	vld1.32	{d17}, [r3]		  ;laden aus fftY;
	vmul.f32	d16, d16, d16 ;fftX[k] * fftX[k];
	cmp	r0, ip
	vmla.f32	d16, d17, d17 ;+ fftY[k] * fftY[k];
	add	r3, r4, r1
	vmul.f32	d16, d18, d16 ;Division dargestellt als Multiplikation;
	add	r1, r1, #8
	fstd	d16, [r3, #0]
	bcc	.L95
	cmp	r5, sl
	mov	r1, sl
\end{lstlisting}


\subsection{Optimierung von MFCC}\label{subsec:optMFCC}

\subsection{Optimierung von Hamming Window}\label{subsec:optHAM}

\subsection{Optimierung der Zero Crossing Rate}\label{subsec:optZCR}



 
