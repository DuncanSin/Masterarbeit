
\section{Optimierung des ARM}
In diesem Kapitel werden die Optimierungen am Code beschrieben, der rein auf dem ARM Cortex-A8 ausgeführt wird. Hierfür werden die in \textbf{Kapitel \ref{subsec:a8}} beschriebenen Hardwareemelemte ausgenutzt.\\
In \textbf{Abschnitt \ref{subsec:armtime}} wird daher als erstes die Laufzeitmessung des gesamten Programms (Extraktion, Prozessierung und Klassifikation) erläutert, um einen Einstiegspunkt für die Optimierung zu extrahieren. In den darauffolgenden Abschnitten werden daraufhin die durchgeführten Optimierungen beschrieben. 

\subsection{Laufzeitmessung des Gesamtprogramms}\label{subsec:armtime}
Für die erste Laufzeitmessung des gesamten Programms (Extraktion, Prozessierung und Klassifikation) wurde dieses mit den in \textbf{Kapitel \ref{ph:neoncomp}} beschriebenen Compileroptionen zur automatischen Generierung von NEON-Code kompiliert. Die dabei resultierten Laufzeiten sind in \textbf{Abbildung \ref{fig:mclneon}} abzulesen.
%
\begin{figure}[htp]
	\centering
		\includegraphics[width=1\textwidth]{../Pictures/mclneon.pdf}
	\caption{Laufzeiten in ms des Musikklassifikators}
	\label{fig:mclneon}
\end{figure} 
%
Wie man aus der Abbildung entnehmen kann, fällt der größte Anteil an der Gesamtlaufzeit in allen vier Messungen (\textit{MCL1 - MCL4}) auf die Extraktionsphase. Hierbei stellt sich jetzt allerdings die Frage, ob das nur an der Kombination aus ARM und NEON liegt oder ob dieses eine generelle Tendenz ist. Darum muss die Laufzeitmessung der genannten Kombination noch mit den Laufzeitmessungen von einer reinen ARM-Implementation und der Kombination aus ARM und VFP-Einheit (vgl. \textbf{Kapitel \ref{ph:vfp}}) verglichen werden. Die Ergebnisse dieser sind in \textbf{Abbildung \ref{fig:armtime}} abzulesen. Diese und alle weiteren Messungen werden am Beispiel des in \textbf{Kapitel \ref{subsec:fset2}} beschriebenen FeatureSets durchgeführt, die Diagramme für die anderen drei FeatureSets sind für den interessierten Leser im Anhang zu finden, aber für diese sind die beschriebenen Tatsachen äquivalent.
%
\begin{figure}[h]
	\centering
		\includegraphics[width=1\textwidth]{../Pictures/fset2AVN.pdf}
	\caption{Laufzeiten in ms des Musikklassifikators für ARM, ARM+VFP und ARM+NEON am Beispiel des FeatureSets 2}
	\label{fig:armtime}
\end{figure} 
%
Aus \textbf{Abbildung \ref{fig:armtime}} lassen sich drei wesentliche Schlüsse ziehen:

\begin{enumerate}
\item Die Extraktionsphase hat in allen drei Fällen den größten Anteil an der Laufzeit
\item Die reine ARM-Implementation hat die schlechteste Laufzeit
\item ARM+VFP und ARM+NEON scheinen gleichwertig zu sein
\end{enumerate}

Die Punkte 1 und 2 kann man so stehen lassen, da diese zu den erwarteten Ergebnissen zählen, aber Punkt 3 verwundert einen doch sehr. Wie kann es sein, dass trotz der in \textbf{Kapitel \ref{subsubsec:neon}} beschriebenen Vorteile der NEON-SIMD-Einheit gegen über der VFP-Einheit, beide Einheiten doch gleichwertig erscheinen? Es soll nochmals erwähnt werden, dass beide Implementationen mit einer Compileroption für die jeweilige Floating Point-Einheit optimiert wurden. Ein Blick in den entstandenen Assemblercode der beiden Implementierungen gibt die Antwort auf die gestellte Frage. Hier finden sich in beiden Fällen nahezu gleiche Codes, das heißt auch die NEON-SIMD-Einheit für nur die rein skalaren Operationen des VFP aus. Dieses erklärt einerseits, warum sich die Laufzeiten der beiden Implementationen nicht wesentlich voneinander unterscheiden und zeigt andererseits, dass es dem Compiler scheinbar nicht möglich ist effektiv für die NEON-SIMD-Einheit optimierten Code zu generieren.\\\\
Da die Extraktionsphase sich als am zeitintensivsten herausgestellt hat, soll diese jetzt näher analysiert werden.\\ 
Wie aus \textbf{Abbildung \ref{fig:1fset2}} zu entnehmen ist, fallt der größte Anteil der Laufzeit der Extraktionsphase mit knapp 60\% auf die Berechnung der FFT.
%
\begin{figure}[h]
	\centering
		\includegraphics[width=1\textwidth]{../Pictures/1fset2.pdf}
	\caption{Detailliertere Laufzeitmessung der Extraktionsphase}
	\label{fig:1fset2}
\end{figure} 
%
Nachdem die FFT als größter Bottleneck identifiziert wurde, stellt sich die Frage welcher Teil der Berechnung die meiste Zeit einnimmt. Wie in \textbf{Kapitel \ref{subsubsec:fft}} beschrieben, besteht die FFT-Berechnung aus drei Teilen:

\begin{itemize}
\item Bit Reverse
\item Butterfly
\item Nachverarbeitung
\end{itemize}  

Eine Analyse dieser drei Teilberechnungen ergibt, dass der größte Anteil an der Laufzeit der Butterfly-Berechnung zufällt, in Zahlen liegt dieser bei knapp 72\%.

\subsection{Libav als Optimierung der FFT}\label{subsec:optFFT}

Im vorherigen Kapitel haben sich folgende Ergebnisse gezeigt:

\begin{enumerate}
\item ARM+NEON ist die schnellste Kombination
\item Die Extraktionsphase nimmt den größten Anteil der Gesamtlaufzeit ein
\item Die FFT nimmt den größten Anteil an der Laufzeit der Extraktionsphase ein
\item Innerhalb der FFT nimmt die Butterfly-Berechnung den größten Anteil ein
\end{enumerate}

Daraus folgt, dass eine erste Optimierung in Richtung der FFT und der NEON-SIMD-Einheit erfolgen sollte.\\
Bibliotheken, die NEON optimierte FFT-Versionen bieten, sind im Internet reichlich vertreten. Für diese Arbeit wurde sich dafür entschieden die weitverbreiteste Bibliothek \textit{Libav} einzusetzen.\\
Libav ist eine opensource Bibliothek zur Audio- und Videoverarbeitung, die neben einer Vielzahl von Audio- und Videocodecs, Prozessierungsalgorithmen für diese und Tools zur Audio- und Videoverarbeitung auch wie schon erwähnt eine NEON optimierte FFT besitzt.
 
\subsubsection{Laufzeitmessung}
Da der Aufbau der FFT-Berechnung (siehe \textbf{Kapitel \ref{subsubsec:libavfft}}) der Libav-Bibliothek an anderer ist, als der der Referenzimplementierung, wäre ein direkter Laufzeitvergleich zwischen Libav-FFT und Referenz-FFT unfair. Hier für wurden die Messungen der drei Kombinationen aus \textbf{Abbildung \ref{fig:armtime}} für die Libav-FFT wiederholt (vgl. \textbf{Abbildung \ref{fig:libavtime}}).
%
\begin{figure}[h]
	\centering
		\includegraphics[width=1\textwidth]{../Pictures/libavtime.pdf}
	\caption{Laufzeitmessung der Libav-FFT für ARM, ARM+VFP und ARM+NEON}
	\label{fig:libavtime}
\end{figure} 
%
Auch hierbei lässt sich erkennen, dass eine reine ARM-Implementation die langsamste Variante ist. Allerdings lässt sich ebenfalls erkennen, dass der Unterschied von der VFP-Implementierung und der NEON-Implementierung sehr deutlich ist, so wie es zu erwarten war. Dass dieser Unterschied hier so deutlich ist, liegt vor allem daran, dass die NEON-Version nicht wie bei der FFT des Referenzcodes mit der Compileroption für NEON-Code erstellt wurde, sondern wie in \textbf{Kapitel \ref{ph:neonasm}} beschrieben per Hand in NEON-Assembler geschrieben wurde.\\Im Vergleich zur Referenzimplementierung lässt sich für die reine ARM-Implementierung ein Speedup von knapp 1,4, für die VFP-Implementierung von 2,2 und für die NEON-Implementierung sogar von 19,2 erkennen. Bei der ARM-Implementierung ist dieses aus der geringeren Komplexität der Libav-FFT erklären, bei den andern Beiden kommt noch eine bessere Ausnutzung der Architektur hinzu.

\subsubsection{Aufbau der FFT}\label{subsubsec:libavfft}
Wie im vorherigen Kapitel schon erwähnt, unterscheiden sich der Aufbau von Libav-FFT und FFT des Referenzcodes stark, was unter anderem eine Komplexitätsreduktion der Butterfly-Berechnung und damit eine geringere Laufzeit mit sich bringt. In diesem Abschnitt wird nun dieser Unterschiedliche Aufbau näher erläutert.\\
Die FFT des Referenzcodes basiert auf den in \textbf{Kapitel \ref{subsubsec:fft}} beschriebenen Reduktionen einer 256-Punkt-FFT auf kleinere FFTs des Radix 2 Der Aufbau der Libav-FFT hingegen basiert auf der Reduktion auf Splitradix-FFTs. Beide FFTs basieren auf dem DIT-Prinzip (vgl. \textbf{Kapitel \ref{ph:dit}}).


\subsubsection{Einbindung}
Die Einbindung der Libav-FFT in den bestehenden FFT-Code ist schier einfach. Eigentlich muss nur die Referenzimplementierung der FFT durch den Aufruf der Libav-FFT ersetzt werden. Hinzu kommt eine Umdefinieren des verwendeten Vektors \textit{source}. Dieser wird um einen benutzerdefinierten  erweitert, der sicher stellt, dass die enthaltenen Werte alle mit 16 bit allokiert sind. Die Definition dieses Allokators ist in \cite{libavtemp} zu finden. Nach der Berechnung der FFT muss abschließend noch eine Auftrennung des resultierenden Vektors in Real- und Imaginärteil geschehen, da das Ergebnis der Libav einen Vektor darstellt, der abwechselt den Real- und Imaginärteil der Ergebnisse enthält.

\subsubsection{Laufzeitmessung nach der FFT-Optimierung mit Libav}

Nach der Optimierung des Bottlenecks FFT wird eine weitere Laufzeitmessung durchgeführt, um nachzuvollziehen, ob dieser Bottleneck verwunden und eventuell neue Bottlenecks aufgetaucht sind. Diese Messung ist in \textbf{Abbildung \ref{fig:postlibav}} zu finden.
%
\begin{figure}[h]
	\centering
		\includegraphics[width=1\textwidth]{../Pictures/postlibav.pdf}
	\caption{Laufzeitmessung nach der FFT-Optimierung}
	\label{fig:postlibav}
\end{figure} 
%
Wie man in \textbf{Abbildung \ref{fig:postlibav}} sieht, ergeben sich nach dieser Optimierung vier Algorithmen die langsamer sind als die neue FFT, hinzu kommt noch ein weiterer Algorithmus aus FeatureSet 3:

\begin{itemize}
\item Octave Spectral Contrast (siehe \textbf{Kapitel \ref{sec:vista}})
\item Magnitude of Sprectrum (\textbf{\ref{subsec:optAOS}})
\item MFCC (\textbf{\ref{subsec:optMFCC}})
\item Hamming Window (\textbf{\ref{subsec:optHAM}})
\item Zero Crossing Rate (siehe \textbf{Kapitel \ref{sec:vista}})
\end{itemize}

Auf die Optimierung von OSC wird im Rahmen dieser Arbeit verzichtet, da 76\% der Laufzeit dieses Features auf die Sortierung fallen. Eine NEON-SIMD-Umsetzung dieser Sortierung würde den Rahmen dieser Arbeit sprengen.\\
Des weiteren wurde auf die Optimierung von ZCR verzichtet. Bei diesem Feature fallen über 90\% auf die Signum-Berechnung, diese ließe sich zwar durch geschicktes Anordnen der drei IF-Bedingungen optimieren, dieses kann sich aber von Musikstück zu Musikstück ändern und wäre rein datenabhängig.


\subsection{Optimierung der Magnitude of Spectrum}\label{subsec:optAOS}

Für die Optimierung der Magnitude of Spectrum wird auf die in \textbf{Kapitel \ref{ph:neonc}} beschriebene Taktik der Codeanpassung zurückgegriffen. Diese Codeanpassung soll es dem Compiler erleichtern stellen zu erkennen, die mit der NEON-SIMD-Einheit parallel berechnet werden können.\\
Hierfür müssen als erstes die Codestellen identifiziert werden, die es dem Compiler nicht ermöglichen eine Einbindmöglichkeit der NEON-SIMD-Einheit festzustellen. Ein Blick in den Instruktionssatz der NEON-SIMD-Einheit ermöglicht es die Wurzelberechnung als eine solche Problemstelle zu identifizieren. Dieses begründet sich auf die Tatsache, dass die NEON-SIMD-Einheit keine Befehle für die Berechnung einer Wurzel besitzt. Da sich die Division beschleunigen ließe, diese aber erst nach der Wurzelberechnung angewandt wird (vgl. \textbf{Formel \ref{eqn:aos}}), wird diese auf mathematischem Weg in die Wurzel gezogen. \textbf{Listing \ref{code:aosc}} zeigt den geänderten C-Code und \textbf{Listing \ref{code:aosasm}} den daraus resultierenden Assemblercode.

\begin{lstlisting}[caption=Codeanpassung der Magnitude of Spectrum, label=code:aosc]
	realv tmp, size2;

	size2 = (realv) size * size;
	for (int k = 0; k < size; k++) {
		tmp = fftX[k] * fftX[k] + fftY[k] * fftY[k];

		temp[k] = tmp / size2;

	}
	for (int k = 0; k < size; k++) {
		amplitude[k] = sqrt(temp[k]);
	}
\end{lstlisting}
Aus den beiden Listings lässt sich erkennen, dass sowohl die Zeile 5 aus \textbf{Listing \ref{code:aosc}} als auch die Division mit der NEON-SIMD-Einheit parallelisiert wurden, was eine kürzere Ausführungszeit bewirkt.
\newpage

\begin{lstlisting}[caption=Resultierender Assemblercode, label=code:aosasm]
	add	r2, r7, r1
	add	r3, r6, r1
	vld1.32	{d16}, [r2]       ;laden aus fftX;
	add	r0, r0, #1
	vld1.32	{d17}, [r3]		  ;laden aus fftY;
	vmul.f32	d16, d16, d16 ;fftX[k] * fftX[k];
	cmp	r0, ip
	vmla.f32	d16, d17, d17 ;+ fftY[k] * fftY[k];
	add	r3, r4, r1
	vmul.f32	d16, d18, d16 ;Division dargestellt als Multiplikation;
	add	r1, r1, #8
	fstd	d16, [r3, #0]
	bcc	.L95
	cmp	r5, sl
	mov	r1, sl
\end{lstlisting}

\subsection{Optimierung von Hamming Window}\label{subsec:optHAM}
Für die Optimierung des Hamming Windows wird eine Optimierung durch den in \textbf{Kapitel \ref{ph:neonint}} beschriebenen Einsatz von Intrinsics gewählt. Hierbei wurden immer vier Multiplikationen der Eingangsdaten mit dem entsprechenden Hamming Window parallelisiert. \textbf{Listing \ref{code:hamc}} zeigt den Referenzcode und \textbf{Listing \ref{code:hamint}} den entsprechenden Code mit NEON-Intrinsics. Die Variable \textit{table[i]} hält hierbei den entsprechenden Wert für $w_{HW}(i)$, wie diese in \textbf{Kapitel \ref{subsubsec:hw}} beschrieben sind.

\begin{lstlisting}[caption=Referenzcode von Hamming Window, label=code:hamc]
	for (unsigned int i = 0; i < size; i++) {
		result[i] = (*signal)[i] * table[i];
	}
\end{lstlisting}

\begin{lstlisting}[caption=Hamming Window mit NEON-Intrinsics, label=code:hamint]
	for (unsigned int i = 0; i < size; i += 4) {
		s4 = vld1q_f32((float32_t*) &(*signal)[i]);
		t4 = vld1q_f32((float32_t*) &table[i]);
		r4 = vmulq_f32(s4, t4);
		vst1q_f32((float32_t*) &result[i], r4);
	}
\end{lstlisting}

In die Variablen \textit{s4} und \textit{t4} werden jeweils vier Werte vom Eingangssignal, bzw. den Hammingwerten geladen und danach parallel mit dem Intrinsic \textit{vmulg\_f32} Multipliziert. Abschließend wird das Ergebnis dieser Multiplikationen (\textit{r4}) in den Ausgangsvektor geschrieben.

\subsection{Optimierung von MFCC}\label{subsec:optMFCC}
Wie in \textbf{Kapitel \ref{subsubsec:mfcc}} beschrieben, besteht die Berechnung des MFCC aus drei Teilen:

\begin{itemize}
\item Einer Akkumulation,
\item einer Logarithmusberechnung
\item und einer anschließenden DCT
\end{itemize}

Zur Optimierung dieses Features muss als erstes der Bottleneck innerhalb dieser Feature-Berechnung identifiziert werden. Ein Detailprofiling dieser Berechnung zeigt, dass der größte Anteil mit knapp 44\% auf die Akkumulation fällt, die übrigen 56\% verteilen sich relativ gleichmäßig auf Logarithmus und DCT.\\
\textbf{Listing \ref{code:mfccc}} zeigt den Referenzcode der Akkumulation innerhalb der MFCC-Berechnung.

\begin{lstlisting}[caption=Referenzcode der Akkumulation innerhalb der MFCC-Berechnung, label=code:mfccc]
for (unsigned int m = 1; m <= M; m++) {
   for (unsigned int k = f_edge_table_bd[m - 1];k <= f_edge_table_bd[m + 1]; k++) {
		log_M[m - 1] += (*signal)[k] * wk[m - 1][k];

   }
}
\end{lstlisting}

Aus diesem Code-Schnipsel lässt sich entnehmen, dass die in den zwei Schleifen enthaltene Akkumulation nicht für jeden Durchlauf gleich oft ausgeführt werden muss. Diese Tatsache führt bei der angestrebten Optimierung mit NEON-Intrinsics zu einem Problem. Im Gegensatz zur vorher beschriebenen Optimierung von Hamming Window kann also nicht einfach der Schleifendurchlauf durch vier geteilt werden.\\
Die Optimierung der MFCC erfolgt daher in fünf Schritten:

\begin{enumerate}
\item Feststellen der benötigten Durchläufe
\item Vier parallele Berechnungen sooft wie möglich
\item Gegebenenfalls noch eine Berechnung von zwei werten parallel
\item Gegebenenfalls noch eine einzelne Berechnung
\item Aufsummierung der Werte der drei vorherigen Schritte
\end{enumerate}

\textbf{Listing \ref{code:mfccint}} zeigt die gewählte Lösung und ersetzt die innere Schleife aus \textbf{Listing \ref{code:mfccc}}. In der Variable \textit{mod} wird die Anzahl der nicht durch vier parallele Rechnungen berechenbaren Durchläufe gespeichert, danach werden in den Zeilen 8-15 so viele parallelen vierfach Berechnung durchgeführt wie möglich. Sollte \textit{mod} größer als 1 sein, also noch zwei parallele Berechnungen möglich sein, werden diese in den Zeilen 17-25 durchgeführt. Wenn danach immer noch eine Berechnung fehlen sollte, wird diese in den Zeilen 27-29 durchgeführt. Abschließend wir werden in Zeile 31 die Einzelergebnisse aufsummiert. 

\begin{lstlisting}[caption=Der Akkumulation innerhalb der MFCC-Berechnung mit NEON-Intrinsics, label=code:mfccint]
	mod = (f_edge_table_bd[m + 1] - f_edge_table_bd[m - 1]+1) % 4;

	memset(&temp[0], 0., temp.size() * sizeof(realv));

	fedtbd = f_edge_table_bd[m + 1];
	fedtbd2 = fedtbd-mod+1;

	r4 = vld1q_f32((float32_t*) &temp[0]);
	for (unsigned int k = f_edge_table_bd[m - 1]; k < (fedtbd - mod); k +=4) {
		s4 = vld1q_f32((float32_t*) &(*signal)[k]);
		w4 = vld1q_f32((float32_t*) &(wk.data()[m - 1])[k]);

		r4 = vmlaq_f32(r4, s4, w4);
	}
	vst1q_f32((float32_t*) &temp[0], r4);

	if (mod > 1) {
		s2 = vld1_f32((float32_t*) &(*signal)[fedtbd2]);
		w2 = vld1_f32((float32_t*) &(wk.data()[m - 1])[fedtbd2]);
		r2 = vld1_f32((float32_t*) &temp[0]);
		t2 = vmla_f32(r2, s2, w2);
		vst1_f32((float32_t*) &temp[0], t2);
		mod -= 2;
		fedtbd2 += 2;
	}

	if (mod == 1) {
		log_M[m - 1] = (*signal)[fedtbd] * wk[m - 1][fedtbd];
	}
	
	log_M[m - 1] += temp[0] + temp[1] + temp[2] + temp[3]+1;
\end{lstlisting}

\subsection{Zwischenevaluation der ARM-Optimierung}
Nach den in den vorherigen Abschnitten durchgeführten Optimierungen wird ein Vergleich der optimierten Algorithmen durchgeführt. In \textbf{Abbildung \ref{fig:endarm}} werden die Laufzeiten in ms/Fenster vor und nach der Optimierung gegenübergestellt.
%
\begin{figure}[h]
	\centering
		\includegraphics[width=1\textwidth]{../Pictures/endarm.pdf}
	\caption{Gegenüberstellung der Laufzeiten der optimierten Algorithmen vor und nach der Optimierung}
	\label{fig:endarm}
\end{figure} 
%
Wie man der Abbildung entnehmen kann, wurde der größte Speedup bei der FFT-Berechnung erreicht. Dieser beträgt, wie schon in \textbf{Kapitel \ref{subsec:optFFT}} erwähnt knapp 19,2. Des weiteren wurden bei Magnitude of Spectrum ein Speedup von 2, bei MFCC ein Speedup von 1,2 und beim Hamming Window von 3,4. Für die gesamte Extraktion des FeatureSets 2 wird ein Speedup von 2,7 erreicht.



 
