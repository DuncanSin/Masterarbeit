\chapter{Grundlagen}
\label{ch:grund}
\rm
In diesem Kapitel werden die Grundlagen  der Audio-Signalklassifikation respektive der Muskklassifikation eingeführt.\\
Dabei werden verschiedene Audio-Merkmale und für diese Arbeit relevante Algorithmen zur Prozessierung und Klassifikation vorgestellt. Abschließend werden die vier verwendeten Musikklassifikationsmethoden erläutert.
\section{Musikklassifikation}\label{sec:mcl}

Musikklassifikation findet im Wesentlichen in drei Schritten statt (vgl. \textbf{Abbildung \ref{fig:mcl}}).
%
\begin{figure}[htp]
	\centering
		\includegraphics[width=1\textwidth]{../Pictures/MCL.pdf}
	\caption{Flussdiagramm der Musikklassifikation}
	\label{fig:mcl}
\end{figure}
%

Im ersten Schritt werden aus den betrachteten Musikstücken in der Extraktionsphase charakteristische Merkmale extrahiert (vgl. \textbf{Kapitel \ref{sec:alg}}). In der Prozessierungsphase, werden die extrahierten Merkmale zu einem Merkmalsvektor zusammengefasst. Im letzten Schritt werden die Merkmalsvektoren anhand eines Klassifikators klassifiziert. Auf diese Weise wird jedem Musikstück eine Musikkategorie (\textit{Genre}) zugewiesen. Eine detaillierte Erläuterung dieser drei Schritte wird im Folgenden gegeben.


\section{Extraktion}\label{subsec:ext}


Zur Extraktion von Merkmalen wird eine zuvor festgelegte Zusammenstellung von Merkmalen (engl. Feature Sets) verwendet. Hierbei kann zwischen Merkmalen aus der Zeit-Domäne und Merkmalen aus der Frequenz-Domäne unterscheiden werden. Das Audio-Signal wird in gleichgroße Fenster eingeteilt, die sich überlappen können. Anschließend werden die zu betrachtenden Merkmale aus diesen Fenstern nacheinander extrahiert, so dass pro Fenster ein Merkmalsergebnis vorliegt. Diese Reihe der einzelnen Ergebnisse wird nachfolgend als Wertereihe bezeichnet. Außerdem wird nur ein Audio-Kanal verwendet. Bei Stereo-Signalen muss daher entweder ein Kanal selektiert oder beide Kanäle gemischt werden. \textbf{Abbildung \ref{fig:signal}} stellt die wesentlichen Parameter der Extraktionsphase heraus, zur Hilfe sind die ersten drei Fenster farblich markiert.

%
\begin{figure}[h]
	\centering
		\includegraphics[width=1\textwidth]{../Pictures/signal.pdf}
	\caption{Signalverlauf mit Extraktionsparametern\cite{haller2008}}
	\label{fig:signal}
\end{figure}
%

Die Größe eines Fensters wird in Anzahl an Audio-Samples angegeben. Eine Fenstergröße von $N=512$ entspricht dabei einer Sampling-Rate von 22050 Hz, also zirka 23 ms. Die Fensterüberlappung wird ebenfalls mit der Sampling-Anzahl angegeben. Typische Werte sind $Nhop=0$ oder $Nhop=\frac{N}{2}$.

 
\subsection{Merkmale}\label{sec:alg}
Merkmale können in zwei Bereiche unterteilt werden. Zum einen in Merkmale, die aus dem Zeitbereich stammen (\textbf{Abschnitt \ref{subsec:zeit}}) und zum anderen in Merkmale, die aus dem Frequenzbereich stammen (\textbf{Abschnitt \ref{subsec:freq}}).\\
Für die nachfolgend vorgestellten Merkmale wird die Notation aus \textbf{Tabelle \ref{tab:note}} verwendet. Ausführliche Definitionen der präsentierten Mermale sind in \cite{haller2008} und \cite{Theimer2008} zu finden.

\begin{table*}[ht]
	\centering
		\begin{tabular}{p{6cm} | c}
			\textbf{Ausdruck} & \textbf{Formel}\\
			\hline
			\hline
			Anzahl der Zeitfenster im Musikstück & $L_{total}~=~\left\lceil \frac{N_{total}}{N} \right\rceil$ \\
			Anzahl der Frequenzwerte & $K$ \\
			Anzahl der Samples im Musikstück & $N_{total}$ \\
			Amplitude der Spektralkomponente & $A(k)~=~\left|X(k)\right|$ \\
			Amplitude der Spektralkomponente im Zeitfenster l & $A^{(l)},~l\in[1,L_{total}]$\\
			Diskrete Fouriertransformation & $X(k)~=~\sum\limits^{N-1}_{n=0}x(n)\cdot W^
			{kn}_N,~W_N~=~e^{-j\frac{2\pi}{N}},~K~=~N$\\
			diskrete Spektralkomponente & $X(k)$ \\
			diskretes Zeitsignal & $x(n),\ n\in[0,N_{total}~-~1]$\\
			Frequenzwert & $k\in[0,~K]$ \\
			Länge eines Zeitfensters & $N$\\
			Samplingfrequenz in Hz & $f_{s}$
		\end{tabular}
	\caption{Tabelle der verwendeten Ausdrücke und Variablen}
	\label{tab:note}
\end{table*}


\subsubsection{Merkmale der Zeit-Domäne}\label{subsec:zeit}

\paragraph{Root Mean Square (RMS)}\label{subsubsec:rms}$\;$ \\
Root Mean Square oder auch das quadratische Mittel normiert die einzelnen Signalenergien innerhalb eines Zeitfensters (\textbf{Formel \ref{eqn:rms}}).

\begin{equation}
	\label{eqn:rms}
	x_{rms}~=~\sqrt{\frac{1}{N}\sum^{N-1}_{n=0}x^{2}(n)}
\end{equation}

\paragraph{Low Energy (LE)}\label{subsubsec:le}$\;$ \\

Low Energy fasst mehrere aufeinander folgende Zeitfenster $n$ zu einem sogenannten Analysezeitraum zusammen und gibt die Rate der Zeitfenster an, deren RMS unter dem Mittel aller RMS im Analysezeitraum liegen (\textbf{Formel \ref{eqn:le}}). Hierfür sei $N_{a}$ die Anzahl der betrachteten Zeitfenster im Analysezeitraum.

\begin{equation}
	\label{eqn:le}
	r_{low}~=~\frac{1}{N_{a}}\sum^{N_{a}-1}_{i=0}u(\mu_{rms}~-~x_{rms}(n))
\end{equation}

mit 

\begin{equation}
\mu_{rms}~=~\frac{1}{N_{a}}\sum^{N_{a}-1}_{i=0}x_{rms}(n)
\end{equation} 

und
 
\begin{equation}
u(x)~=~\left\{ \begin{array}{ll} 
1 & \textrm{für } x~>~0 \\
0 & \textrm{für } x~\leq~0\\
\end{array}\right.
\end{equation} 
 

\paragraph{Zero Crossing Rate (ZCR)}\label{subsubsec:zcr}$\;$ \\

Bei der Zero Crossing Rate werden die Auftreten von Vorzeichenwechseln innerhalb eines Zeitfensters berechnet. Diese Rate gibt ein Maß für den hochfrequenten Anteil des Signals an (\textbf{Formel \ref{eqn:zero}}).

\begin{equation}
	\label{eqn:zero}			   r_{zcr}~=~\frac{1}{2(N~-~1)}\sum^{N-2}_{n=0}\left|sgn~x(n~+~1)~-~sgn~x(n)\right|
\end{equation}

\subsubsection{Merkmale der Frequenz-Domäne}\label{subsec:freq}

\paragraph{Hamming Window (HAM)}\label{subsubsec:hw}$\;$ \\

Hamming Window bezeichnet eine andere Form eines Fensters als der Standartform eines quadratischen Fensters. Das Hamming Window ergibt sich nach \textbf{Formel \ref{eqn:hw}}.

\begin{equation}\label{eqn:hw}
w_{HW}(n)~=~0,54-0,46\cdot \cos \left( \frac{2 \pi n}{N-1} \right)
\end{equation}

\paragraph{Fast Fourier Transformation (FFT)}\label{subsubsec:fft}$\;$ \\

Unter dem Begriff \textit{Fast Fourier Transformation} werden Algorithmen zusammengefasst, die eine schnelle und effiziente Berechnung von \textit{diskreten Fourier-Transformationen (DFT)} bieten. Diese effizienten Algorithmen kann man im Wesentlichen in zwei Gruppen unterteilen, diejenigen die mit Zeitzerlegung (\textbf{\ref{ph:dit}}) und diejenigen die mit Frequenzzerlegung (\textbf{\ref{ph:dif}}) arbeiten.\\
Für beide Gruppen von Algorithmen wird immer eine Operation benötigt, die entweder die Eingänge oder die Ausgänge in einer bestimmten Form sortiert. Diese Operation wird als \textit{Bitumkehrordnung} oder engl. \textit{bit-reversed order} bezeichnet (\textbf{\ref{ph:bit}}).

\subparagraph{FFT mit Zeitzerlegung (DIT)}\label{ph:dit}$\;$ \\

Bei einer FFT mit Zeitzerlegung wird durch Ausnutzen der Symmetrie- und Periodizitätseigenschaften der komplexen Exponenzialfolge $W^{kn}_N= e^{j\left(\frac{2\pi}{N}\right)kn}$ das Signal $x(n)$ in immer kleiner werdende Teilfolgen zerlegt. Im ersten Schritt einer solche Zerlegung werden gerade und ungerade Indizes getrennt, so dass zwei Teilfolgen entstehen (\textbf{Formel \ref{eqn:dit1}}).

\begin{equation}
	\label{eqn:dit1}			   
	X[k]~=~ \sum_{n gerade} x[n]W^{nk}_N~+~ \sum_{n ungerade} x[n]W^{nk}_N
\end{equation}

Substituiert man nun $n = 2r$ für die gerade und $n=2r+1$ für die ungerade Teilfolge, so entsteht \textbf{Formel \ref{eqn:dit2}}.

\begin{equation}
	\label{eqn:dit2}
	\begin{split}			   
	X[k]~=~ \sum^{(N/2)-1}_{r = 0} x[2r]W^{2rk}_N~+~ \sum^{(N/2)-1}_{r = 0} x[2r+1]W^{(2r+1)k}_N \\
	~=~\sum^{(N/2)-1}_{r = 0} x[2r](W^2_N)^{rk}~+~ \sum^{(N/2)-1}_{r = 0} x[2r+1](W^2_N)^{rk} 
	\end{split}
\end{equation}

Da $W^2_N=W_{N/2}$ gilt kann man \textbf{Formel \ref{eqn:dit2}} vereinfachen zu \textbf{Formel \ref{eqn:dit3}}.

\begin{align}
	\label{eqn:dit3}			   
	X[k]~=~ \sum^{(N/2)-1}_{r = 0} x[2r]W^{rk}_{N/2}~+~ W^k_N\sum^{(N/2)-1}_{r = 0} x[2r+1]W^{rk}_{N/2} \\
	~=~G[k]~+~W^k_NH[k]
\end{align}

Eine ähnliche Vereinfachung kann nun für beide Teilfolgen durchgeführt werden, bis am ende nur noch 2-Punkt DFTs durchgeführt werden müssen.\\
Diese 2-Punkt DFTs führen zu einem Signalflussgraph, wie er in \textbf{Abbildung \ref{fig:BF-DIT}} dargestellt ist.\\
%
\begin{figure}[ht]
	\centering
		\includegraphics[scale=0.5]{../Pictures/BF-DIT.pdf}
	\caption{Signalflussgraph eines vereinfachten Butterfly einer DIT\cite{Opp1999}}
	\label{fig:BF-DIT}
\end{figure}
%
Aufgrund der Form dieses Signalflussgraphen wird die dargestellte Operation als \textit{Butterfly} bezeichnet. Der vollständige Signalflussgraph einer 8-Punkte DFT mit Zeitzerlegung ist in \textbf{Abbildung \ref{fig:dit}} zu sehen.\\
%
\begin{figure}[ht]
	\centering
		\includegraphics{../Pictures/DIT.pdf}
	\caption{Signalflussgraph einer 8-Punkte DFT mit Zeitzerlegung\cite{Opp1999}}
	\label{fig:dit}
\end{figure}
%
\subparagraph{FFT mit Frequenzzerlegung (DIF)}\label{ph:dif}$\;$ \\

Alternativ zur Zeitzerlegung einer FFT kann auch eine Zerlegung der Ausgangsfolge $X[k]$ durchgeführt werden, welche als Frequenzzerlegung bezeichnet wird. Hierbei werden wie in \textbf{(\ref{ph:dit})} im ersten Schritt aus der Folge $X[k]$ (\textbf{Formel \ref{eqn:dif1}}) Teilfolgen mit geraden und ungeraden Indizes gebildet (\textbf{Formel \ref{eqn:dif2}}).

\begin{equation}
	\label{eqn:dif1}
	X[k]~=~\sum^{N-1}_{n=0}x[n]W^{nk}_N, ~k=0,1,...,N-1	
\end{equation}

\begin{equation}
	\label{eqn:dif2}
	\begin{split}
	X[2r]~=~\sum^{N-1}_{n=0}x[n]W^{n(2r)}_N, ~r=0,1,...,\frac{N}{2}-1	\\
	X[2r+1]~=~\sum^{N-1}_{n=0}x[n]W^{n(2r+1)}_N, ~r=0,1,...,\frac{N}{2}-1	
	\end{split}
\end{equation}

Diese beiden Folgen können auch in der in \textbf{Formel \ref{eqn:dif3}} dargestellten Form geschrieben werden.

\begin{subequations}
	\label{eqn:dif3}
	\begin{align}
		X[2r]~=~\sum^{(N/2)-1}_{n=0}x[n]W^{2nr}_N~+~\sum^{N-1}_{n=N/2}x[n]W^{2nr}_N\label{eqn:dif3a}\\
		X[2r+1]~=~\sum^{(N/2)-1}_{n=0}x[n]W^{n(2r+1)}_N~+~\sum^{N-1}_{n=N/2}x[n]W^{n(2r+1)}_N\label{eqn:dif3b}
 	\end{align}
\end{subequations}

Führt man an den zweiten Summen der \textbf{Formel \ref{eqn:dif3}} eine Variablensubstitution durch so er gibt sich für (\textbf{\ref{eqn:dif3a}}):

\begin{equation}
	\label{eqn:dif4}
	X[2r]~=~\sum^{(N/2)-1}_{n=0}x[n]W^{2nr}_N~+~\sum^{(N/2)-1}_{n=0}x[n+(N/2)]W^{2r(n+(N/2)}_N
\end{equation}

Und für die zweite Summe aus (\textbf{\ref{eqn:dif3b}}):

\begin{equation}
	\label{eqn:dif5}
	\begin{split}
		\sum^{N-1}_{n=N/2}x[n]W^{n(2r+1)}_N ~=~ \sum^{(N/2)-1}_{n=0}x[n+(N/2)]W^{[n+(n/2)](2r+1)}_N \\
		=~W^{(N/2)(2r+1)}_N \sum^{(n/2)-1}_{n=0}x[n+(N/2)]W^{n(2r+1)}_N \\
		=~-\sum^{(N/2)-1}_{n=0}x[n+(N/2)]W^{n(2r+1)}_N 
	\end{split}
\end{equation}

Die letzte Umformung aus \textbf{Formel \ref{eqn:dif5}} verwendet die Tatsache, dass $W^{(N/2)2r}_N=1$ und $W^{(N/2)}_N=0$ gilt.\\
Fasst man nun jeweils die Summationen der beiden Teilfolgen zusammen und nutzt wie in (\textbf{\ref{ph:dit}}) $W^2_N=W_{N/2}$, kann man die Teilfolgen auch wie in \textbf{Formel \ref{eqn:dif6}} darstellen.

\begin{equation}
	\label{eqn:dif6}
	\begin{split}
		X[2r]~=~\sum^{(N/2)-1}_{n=0}(x[n]+x[n+(N/2)])W^{rn}_{N/2}, ~r=0,1,...,\frac{N}{2}-1 \\
		X[2r+1]~=~\sum^{(N/2)-1}_{n=0}(x[n]+x[n+(N/2)])W^{rn}_{N/2}W^n_N, ~r=0,1,...,\frac{N}{2}-1
	\end{split}
\end{equation}

In \textbf{Abbildung \ref{fig:BF-DIF}} ist der aus \textbf{Formel \ref{eqn:dif6}} abgeleitete Signalflussgraph der \textit{Butterfly}-Operation zu sehen und \textbf{Abbildung \ref{fig:dif}} zeigt den vollständigen Signalflussgraph einer 8-Punkte DFT nach Frequenzzerlegung.\\
%
\begin{figure}[ht]
	\centering
		\includegraphics[scale=0.5]{../Pictures/BF-DIF.pdf}
	\caption{Signalflussgraph eines vereinfachten Butterfly einer DIF\cite{Opp1999}}
	\label{fig:BF-DIF}
\end{figure}
%
\begin{figure}[ht]
	\centering
		\includegraphics{../Pictures/DIF.pdf}
	\caption{Signalflussgraph einer 8-Punkte DFT mit Frequenzzerlegung\cite{Opp1999}}
	\label{fig:dif}
\end{figure}
%
\subparagraph{Bitumkehrungordnung (bit-reversed order)}\label{ph:bit}$\;$ \\

Wie man in \textbf{Abbildung \ref{fig:dit}} und \textbf{Abbildung \ref{fig:dif}} gut erkennen kann, liegen entweder die Eingänge oder die Ausgänge in einer nicht numerisch sortierten Form vor. Diese Sortierung ergibt sich aus den in (\textbf{\ref{ph:dit}}) und (\textbf{\ref{ph:dif}}) gezeigten Algorithmen, folgt aber immer dem selben Schema.\\ 
Es werden die Indizes des Ein- oder Ausgangs anhand ihrer Bits vom \textit{Least Significant Bit (LSB)} zum \textit{Most Significant Bit (MSB)} sortiert, so dass pro Ebene in der oberen Hälfte die Indizes stehen, die beim momentan betrachteten Bit eine 0 aufweisen.\\
Dieses Prinzip soll in \textbf{Tabelle \ref{tab:bit}} für 3-Bit lange Indizes veranschaulicht werden.\\
%
\begin{table}[ht]
	\centering
		\begin{tabular}{c | c | c | c}
			Position (dezimal) & Position (binär) & "`bit reversal"' (binär) & "`bit reversal"' (dezimal) \\
			\hline\hline
			0 & 000 & 000 & 0\\
			1 & 001 & 100 & 4\\
			2 & 010 & 010 & 2\\
			3 & 011 & 110 & 6\\
			4 & 100 & 001 & 1\\
			5 & 101 & 101 & 5\\
			6 & 110 & 011 & 3\\
			7 &	111 &	111 &	7
		\end{tabular}
	\caption{Bitumkehrordnung für 3-Bit Indizes\cite{haller2008}}
	\label{tab:bit}
\end{table}
%

\subparagraph{Fourier-Transformation von Audio-Signalen}$\;$ \\
In der Musikklassifikation liegen Audio-Samples als reelwertige Wertefolgen vor. DFT- und FFT-Algorithmen sind aber für komplexwertige Eingangsfolgen definiert. Um nun Audio-Samples mit einer DFT oder FFT zu transformieren, müssen diese in komplexwertige Folgen umdefiniert werden. Die einfachste Methode dieses zu erreichen, ist den Imaginär-Teil als Null anzunehmen. Dieses führt dazu, dass die sich ergebenden Fourier-Koeffizienten in der  konjugiert komplexe Achsensymmetrien aus \textbf{Formel \ref{eqn:achs}} vorliegen.

\begin{equation}
\label{eqn:achs}
X[k]=X[-k]^*=X[N-k]^*~0\leq n \le N
\end{equation}  

Dieses hat zu Folge, dass für die Weiterverarbeitung der Fourier-Koeffizienten nur die Hälfte der berechneten Koeffizienten benötigt wird. Daraus folgt, dass für die Berechnung einer DFT oder FFT bei reellwertigen Eingangsfolgen der Länge N eine halb so große DFT beziehungsweise FFT der Länge $\frac{N}{2}$ verwendet werden kann. Eine solche Transformation setzt eine anschießende Nachverarbeitung der Fourier-Koeffizienten voraus, die die erwarteten Real- und Imaginärteile in die richtige Reihenfolge gebracht werden. Um dieses zu erreichen muss als erstes die reellwertige Eingangsfolge $x[n]$ der Länge N mit Hilfe von \textbf{Formel \ref{eqn:comp}} in eine komplexwertige Eingangsfolge $x^+[n]$ konvertiert werden.

\begin{equation}
\label{eqn:comp}
\begin{split}
Re\left\lbrace x^+[n]\right\rbrace =x[2n]\\
Im\left\lbrace x^+[n]\right\rbrace =x[2n+1]
\end{split}
\end{equation}

Aus der so entstandenen Eingangsfolge $x^+[n]$ können die $\frac{N}{2}$ Fourier-Koeffizienten $X^+[k]$ berechnet werden. Unter Berücksichtigung von

\begin{equation}
X^+\left[\frac{N}{2}\right]=X^+[0]
\end{equation} 

können durch \textbf{Formel \ref{eqn:koeff}} die ersten $\frac{N}{2}$ Fourier-Koeffizienten bestimmt werden.

\begin{equation}
\label{eqn:koeff}
X[k]=\frac{1}{2}\left(\left(X^+[k]+X^+\left[\frac{N}{2}-k\right]^*\right)-W^k_N\left(X^+[k]-X^+\left[\frac{N}{2}-k\right]^*\right)\right)~0\leq k \le \frac{N}{2}
\end{equation}

\paragraph{Magnitude of Spectrum (MAG)}\label{subsubsec:aos}$\;$ \\
Bei der Magnitude of Spectrum werden die normalisierten Spektralkomponenten eines Fenster berechnet. \\
Hierfür wird zu erst der Betrag der diskreten Transformierten berechnet, welche danach durch die Größe des betrachteten Fensters geteilt werden (\textbf{Formel \ref{eqn:aos}}).

\begin{equation}
	\label{eqn:aos}			   
	A(k)~=~\frac{\sqrt{\Re\left[X(k)\right]^2+\Im\left[X(k)\right]^2}}{N}
\end{equation}

\paragraph{Chroma Vektor (CV)}\label{subsubsec:cv}$\;$ \\

Der Chroma Vektor fasst alle Spektralkomponenten einer Tonhöhe und alle Frequenzen zu einer Oktave zusammen. Hierbei werden alle spektralen Amplituden des gleichen Halb- oder Vierteltons aufsummiert (\textbf{Formel \ref{eqn:cv}}).

\begin{equation}
	\label{eqn:cv}			   
	A_{chroma}\left(\widetilde{k}\right)~=~\sum_{k:~p(k)=\widetilde{k}} A(k)
\end{equation}

Z.B. für Vierteltöne gilt

\[p(k)~=~\left\lfloor 24~log_{2}\left(\frac{2k}{N}\frac{f_{s}}{f_{1}}\right) \right\rfloor~mod~24\textrm{ und }f_{1}~=~440~Hz \]

Für Halbtöne müsste 24 durch 12 ersetzt werden.

\paragraph{Amplitude Of Maximum In Chromagram (AOMIC)}\label{subsubsec:aomic}$\;$ \\

Die maximale Amplitude des Chromagrams gibt den maximalen Chroma Vektor an und stellt daher die Stärke eines Tons in verschiedenen Oktavstufen dar (\textbf{Formel \ref{eqn:aomic}}).

\begin{equation}
	\label{eqn:aomic}			   
	A_{maxchroma}~=~\max_{\widetilde{k}}~A_{chroma}\left(\widetilde{k}\right)
\end{equation}

\paragraph{Mel Frequency Cepstral Coefficients (MFCC)}\label{subsubsec:mfcc}$\;$ \\

Das Cepstrum ist definiert als die Fouriertransformation (oder die DCT) des logerithmierten Amplitudenspektrums.\\
Normalerweise wird ein Cepstrum auf der Basis des Frequenzspektrums berechnet, für die Berechnung der MFCC wird allerdings das Mel-Band zugrunde gelegt. Das Mel-Band basiert auf der Mel-Skala, die als psychoakustische Maßeinheit definiert ist. Wird zum Beispiel eine Frequenz als doppelt so hoch wahrgenommen wie eine festgelegte Referenzfrequenz, so wird auf der Mel-Skala diesem auch der doppelte Wert der Referenzfrequenz zugewiesen. Die hierfür verwendete Referenzfrequenz liegt bei 1000 Hz.\\
Soll nun eine Frequenz $f$ in den zugehörigen Mel-Wert $m$ umrechnen werden, wird hierfür die \textbf{Formel \ref{eqn:mel}} verwendet.

\begin{equation}
	\label{eqn:mel}			   
	m~=~2595 \log_{10} \left(1+\frac{f}{700}\right)
\end{equation}

Die Berechnung der MFCC wird in 4 Schritten durchgeführt.\\
Als Erstes wird wie bei allen Features des Frequenzbereiches die Spektralkomponenten durch eine Fouriertransformation berechnet. Der zweite Schritt besteht in einer Bandpassfilterung dieser Spektralkomponenten nach \textbf{Formel \ref{eqn:melm}}.

\begin{equation}
	\label{eqn:melm}			   
	M(k')~=~\sum\limits^{\frac{K}{2}-1}_{k=0}A(k)\cdot w_{k'}(k)
\end{equation}

Hierbei beschreibt $w_{k'}(k)$ Dreiecksfenster, deren Breite für wachsendes $k$ zunehmen. Im Normalfall werden für diese Transformation in das Mel-Band 12 oder 24 Dreiecksfenster verwendet, wobei die Anzahl der Dreiecksfenster gleichzeitig die Auflösung der Transformation beschreibt.\\
Im nächsten Schritt wird der Logarithmus von $M(k')$ gebildet. Abschließend wird zur Berechnung der MFCC eine Diskrete Cosinus Transformation (DCT) durchgeführt.\\
Wird die Bandpassfilterung mit 12 Dreiecksfenstern durchgeführt, liefert dieser Algorithmus einen Ergebnisvektor mit 13 Komponenten. 

\paragraph{Normalized Audio Spectrum Envelope (NASE)}\label{subsubsec:nase}$\;$ \\

Der Normalized Audio Spectrum Envelope (NASE) gibt Auskunft über das Energiespektrum jedes Fensters. Hierbei wird pro Fenster ein Vektor generiert, bei dem jedes Vektorelement die normalisierte, quadrierte Magnitude eines definierten Frequenz-Unterbandes entspricht.\\
Die Frequenz-Unterbänder spannen sich logarithmisch zwischen 62.4 Hz ("`loEdge"') und 16 kHz ("`hiEdge"') über 8 Oktaven. Die Anzahl $B$ von Unterbändern wird hierbei mit

\begin{equation}
	\label{eqn:naseb}			   
	B~=~\frac{8}{r}
\end{equation}
berechnet, wobei $r$ für die Spektralauflösung steht und 

\begin{equation}
	\label{eqn:naser}			   
	r~=~2^j Oktaven,~-4\leq j \leq 3
\end{equation}
gilt (vgl. \textbf{Abbildung \ref{fig:nase}}).

\begin{figure}[htbp]
	\centering
		\includegraphics[width=1.00\textwidth]{../Pictures/NASE-coeff.pdf}
	\caption{NASE Unterbänder für eine spektrale Auflösung von $\frac{1}{2}$ \cite{Lee2009}}
	\label{fig:nase}
\end{figure}

Die Berechnung der einzelnen NASE-Werte erfolgt hierbei in drei Schritten.\\
Als erstes wird für jedes Unterband $b$ der Audio Spectral Envelope (ASE) nach der in \textbf{Formel \ref{eqn:ase}} gegebenen Formel berechnet.

\begin{equation}
	\label{eqn:ase}			   
	ASE(b)~=~\sum^{hiKb}_{k=loKb}P(k),~0\leq b \leq B+1
\end{equation}

Danach werden diese ASE-Werte nach \textbf{Formel \ref{eqn:asedb}} in Dezibelwerte umgerechnet.

\begin{equation}
	\label{eqn:asedb}			   
	ASE_{dB}(b)~=~10\log_{10}(1+ASE(b)),~0 \leq b \leq B+1
\end{equation}

Anschließend wird aus diesen Werten der NASE-Wert für die einzelnen Unterbänder $b$ berechnet (\textbf{Formel \ref{eqn:nase}}).

\begin{equation}
	\label{eqn:nase}			   
	NASE(b)~=~\frac{ASE_{dB}(b)}{R},~0\leq b \leq B+1
\end{equation}

Hierbei steht $R$ für den normierten RMS-Wert, der nach \textbf{Formel \ref{eqn:naserms}} berechnet wird.

\begin{equation}
	\label{eqn:naserms}			   
	R~=~\sqrt{\sum^{B+1}_{b=0}\left(ASE_{dB}(b)\right)^2}
\end{equation}

Aus den einzelnen NASE-Werten der einzelnen Unterbänder wird abschließend der Ergebnisvektor $X_{NASE}$ gebildet (\textbf{Formel \ref{eqn:nasex}}).

\begin{equation}
	\label{eqn:nasex}			   
	x_{NASE}~=~\left[R,NASE(0),NASE(1),...,NASE(B+1)\right]^T
\end{equation}

\paragraph{Octave Spectral Contrast (OSC)}\label{subsubsec:osc}$\;$ \\

Beim Octave Spectral Contrast wird das Frequenzspektrum als erstes mit Bandpass-Filtern in Unterbänder aufgeteilt (siehe \textbf{Tabelle \ref{tab:osc}}. Danach werden für jedes Unterband \textit{spektrale Peaks} (\textbf{Formel \ref{eqn:peak}}) und \textit{spektrale Valleys}(\textbf{Formel \ref{eqn:valley}}) berechnet, wobei Peaks den harmonischen Komponenten und Valleys nicht-harmonischen Komponenten oder Rauschen des Unterbandes $b$ entsprechen. Hierbei werden die Power Spektren $P_{b,n}$ vorher so sortiert, dass $P_{b,1}\geq P_{b,2}\geq ... \geq P_{b,n}$ gilt.\\
\begin{table}[ht]
	\centering
		\begin{tabular}{c | c}
			Filternummer & Frequenzbereich (Hz)\\
			\hline\hline
			0 & [0,0]\\
			1 & (0,100]\\
			2 & (100, 200]\\
			3 & (200, 400]\\
			4 & (400, 800]\\
			5 & (800, 1600]\\
			6 & (1600, 3200]\\
			7 & (3200, 6400]\\
			8 & (6400, 12800]\\
			9 & (12800, 22050]\\
			
		\end{tabular}
	\caption{Frequenzbereiche der Bandpass-Filter bei 44.1 kHz Samplingfrequenz\cite{Lee2009}}
	\label{tab:osc}
\end{table}
%
\begin{equation}
	\label{eqn:peak}			   	
	Peak(b)~=~\log\left(\frac{1}{\alpha N_b}\sum\limits^{\alpha N_b}_{i=1}P_{b,i}\right)
\end{equation}
\begin{equation}
	\label{eqn:valley}			   	
	Valley(b)~=~\log\left(\frac{1}{\alpha N_b}\sum\limits^{\alpha N_b}_{i=1}P_{b,N_b - i+1}\right)
\end{equation}
In diesem Zusammenhang ist $\alpha$ ein Nachbarschaftsfactor, der in der Literatur mit 0,2 angenommen wird. Der spektrale Kontrast eines Unterbandes errechnet sich nun als Differenz von $Peak(b)$ und $Valley(b)$ (\textbf{Formel \ref{eqn:oscsc}}).
\begin{equation}
	\label{eqn:oscsc}			   	
	SC(b)~=~Peak(b)~-~Valley(b)
\end{equation}
und der resultierende Featurevektor $x_{OSC}$ abschließend aus den Valleys und spektralen Kontrasten eines Audioframes (\textbf{Formel \ref{eqn:osc}}).

\begin{equation}
	\label{eqn:osc}			   	
	x_{OSC} = \left[Valley(0=,...,Valley(B-1),SC(0),...SC(B-1)\right]^T
\end{equation}

%\subsubsection{Power Spectrum}\label{subsubsec:ps}
%
%Das Power Spectrum berechnet sich indem man den Logarithmus des Amplitudenspektrums berechnet (\textbf{Formel \ref{eqn:ps}})\cite{haller2008}.
%
%\begin{equation}
%	\label{eqn:ps}			   	
%	S(k)~=~10\cdot\log\limits_{10}\left(\frac{1}{N}A^2(k)\right)
%\end{equation}



\paragraph{Spectral Centroid (SC)}\label{subsubsec:sc}$\;$ \\

Der Spectral Centroid gibt den Schwerpunkt des Amplitudenspektrums des Signals an (\textbf{Formel \ref{eqn:sc}}).

\begin{equation}
	\label{eqn:sc}			   	S_{centroid}~=~\frac{\sum\limits^{\frac{K}{2}-1}_{k=0}k~A(k)}{\sum\limits^{\frac{K}{2}-1}_{k=0}A(k)} 
\end{equation}

\paragraph{Spectral Crest Factor (SCF)}\label{subsubsec:scf}$\;$ \\

Der Spectral Crest Factor stellt ein Maß der spektralen Flachheit eines Frequenzbandes dar und ist im Wertebereich $\left[1,\infty\right]$ definiert. Hierbei bedeutet 1, dass alle Spektralamplituden gleich sind und $\infty$ das gar keine Flachheit existiert (\textbf{Formel \ref{eqn:scf}}).\\
Dieser Faktor wird auf folgenden Frequenzbändern berechnet:
\begin{itemize}
	\item 250 - 500 Hz ($k_{1l}$ - $K_{1u}$)
	\item 500 - 1000 Hz ($k_{2l}$ - $K_{2u}$)
	\item 1000 - 2000 Hz ($k_{3l}$ - $K_{3u}$)
	\item 2000 - 4000 Hz ($k_{4l}$ - $K_{4u}$)
\end{itemize}


\begin{equation}
	\label{eqn:scf}			   
	S_{crest}~=~frac{\max\limits_{k\in\left[k_{il},k_{iu}\right]}A(k)}{\frac{1}{k_{iu}~-~k_{il}~+~1}\sum\limits^{k_{iu}}_{k=k_{il}}A(k)}
\end{equation}

\paragraph{Spectral Flux (SF)}\label{subsubsec:sf}$\;$ \\

Der Spectral Flux ist definiert als die quadrierte Differenz zwischen den normalisierten Betragsspektren von zwei aufeinander folgenden Zeitfenstern (\textbf{Formel \ref{eqn:sf}}).

\begin{equation}
	\label{eqn:sf}			   
	S_{flux}~=~\frac{2}{K}\sum\limits^{\frac{K}{2}-1}_{k=0}\left( A^{(l)}(k)~-~A^{(l-1)}(k)\right)^2
\end{equation}


\paragraph{Spectral Rolloff (SR)}\label{subsubsec:sr}$\;$ \\

Als Spectral Rolloff bezeichnet man der Frequenzwert ($k_{rolloff}$) unter dem sich eine bestimmte Prozentzahl ($p_{rolloff}$) der Spektralwerte konzentrieren (\textbf{Formel \ref{eqn:sr}}). 

\begin{equation}
	\label{eqn:sr}			   
	\sum^{k_{rolloff}}_{k=0}A(k)~=~p_{rolloff}~\cdot~\sum^{\frac{K}{2}-1}_{k=0}A(k)
\end{equation}

\paragraph{Sub-Band Energy Ratio (SBER)}\label{subsubsec:sber}$\;$ \\

Die Sub-Band Energy Ratio gibt die Verteilung der Spektralenergie auf die Frequenzintervalle $\left[0,\frac{f_s}{16}\right)$,$\left[\frac{f_s}{16},\frac{f_s}{8}\right)$,$\left[\frac{f_s}{8},\frac{f_s}{4}\right)$ und $\left[\frac{f_s}{4},\frac{f_s}{2}\right)$ an und kann in Indexbereiche $\left[0,\frac{K}{16}\right)$,$\left[\frac{K}{16},\frac{K}{8}\right)$,$\left[\frac{K}{8},\frac{K}{4}\right)$ und $\left[\frac{K}{4},\frac{K}{2}\right)$ überführt werden (\textbf{Formel \ref{eqn:sber}}).

\begin{equation}
	\label{eqn:sber}			   
	S_1~=~\frac{\sum\limits^{\frac{K}{16}-1}_{k=0}A^2(k)}{\sum\limits^{\frac{K}{2}-1}_{k=0}A^2(k)},~S_2~=~\frac{\sum\limits^{\frac{K}{8}-1}_{k=\frac{K}{16}}A^2(k)}{\sum\limits^{\frac{K}{2}-1}_{k=0}A^2(k)},S_3~=~\frac{\sum\limits^{\frac{K}{0}-1}_{k=\frac{K}{8}}A^2(k)}{\sum\limits^{\frac{K}{2}-1}_{k=0}A^2(k)},S_1~=~\frac{\sum\limits^{\frac{K}{2}-1}_{k=\frac{K}{4}}A^2(k)}{\sum\limits^{\frac{K}{2}-1}_{k=0}A^2(k)}
\end{equation}

\section{Prozessierung}\label{subsec:proc}
Klassifikationsalgorithmen setzen eine festgelegte Anzahl von Variablen voraus, mit welchen Musikstücke dargestellt werden. Da Mustikstücke z.B. unterschiedliche Laufzeiten aufweisen, ist auch die Anzahl extrahierter Merkmale verschieden. Daher ist die Erstellung von Merkmalsvektoren erforderlich, die die Merkmale nach zum Beispiel statistischen Eigenschaften zusammenfasst. Hierdurch wird außerdem die zu speichernde Datenmenge pro Musikstück reduziert.\\
Zwei in dieser Arbeit eingesetzte Methoden werden im Folgenden vorgestellt.

\subsection{Running Mean and Runnind Deviation (RMD)}

Diese Prozessierungsmethode basiert auf der Berechnung von Mittelwert und Abweichung für jedes Merkmalelement. Diese Datenreduktion geschieht in zwei Schritten.\\
Im erste Schritt wird die Wertereihe eines Merkmals in gleichgroße Fenster der Länge L unterteilt. Danach wird für jedes Fenster Mittelwert und Abweichung berechnet, so dass zwei gleich lange Wertereihen pro Merkmal-Element entstehen, die den Mittelwerten und Abweichungen über den Zeitverlauf entsprechen.\\
Im zweiten Schritt werden von diesen Wertereihen ebenfalls Mittelwert und Abweichung bestimmt, so dass am Ende jedes Merkmal durch vier statistische Werte repräsentiert wird.

\subsection{Modulation Spectral Analysis (MDA)}
Diese Prozessierungsmethode basiert auf der Ermittlung von statistischen Daten aus der spektralen Dynamik eines Merkmals. Hierbei wird von D Elementen pro Vektor ausgegangen. Die Prozessierung wird in vier Schritten durchgeführt.\\
Im ersten Schritt wird jede Elementreihe eines Merkmals in k gleichgroße Fenster der Länge L unterteilt, die sich um 50\% überlappen. Anschließend werden diese mit Hilfe einer FFT in den Frequenzbereich transformiert.\\
Im zweiten Schritt werden aus diesen $D\cdot k$ Fourier-Spektren Betragsspektren berechnet und diese für jedes Merkmalselement gemittelt.\\
Die gemittelten Betragsspektren werden anschließend logarithmisch in acht Subbänder unterteilt. Aus dieser Unterteilung wird eine Dx8-Matrix erstellt in der für jedes Element der kleinste im Subband vorkommende Betrag (\glqq Valley\grqq) und die Differenz vom größten und kleinsten Betrag (\glqq Contrast\grqq) gespeichert wird.\\
Im vierten Schritt werden von allen Valley- und Contrast-Werten Mittelwert und Abweichung berechnet. Hierbei erfolgt die Berechnung sowohl zeilen- als auch spaltenweise.


\section{Klassifikation}\label{subsec:cla}
Während der Klassifikation weist ein Klassifikator einem Merkmalsvektor respektive dem dazu gehörigen Musikstück eine Musikkategorie zu. Hierfür ist ein Klassifikationsmodell erforderlich, das in einer sogenannten Trainingsphase zu erstellen ist. Die Trainingsphase setzt bereits vorklassifizierte Merkmalsvektoren voraus, so dass die Anzahl und Bezeichnungen der Kategorien bzw. Klassen festgelegt wird und der Klassifikator lernen kann, wie er zwischen Klassen anhand der Vektoren unterscheiden kann.\\
Das Prinzip soll anhand der Support Vector Maschine (SVM) erklärt werden.
\\\\
Zur Vereinfachung wird angenommen, dass die Vektoren nur zwei Elemente besitzen und nur zwischen zwei Kategorien zu unterscheiden ist. Die Vektoren lassen sich in einem Merkmalsraum darstellen, der aufgrund der Elementanzahl ebenfalls zweidimensional ist.
%
\begin{figure}[htp]
	\centering
		\includegraphics[width=1\textwidth]{../Pictures/SVM.pdf}
	\caption{Beispiel für eine SVM mit a) zweidimensionaler und b) mehrdimensionaler Hyperebene\cite{Leimig2009}}
	\label{fig:svm}
\end{figure}
%
Der SVM-Klassifikator sucht in der Trainingsphase nach einer Hyperebene, die die Vektoren unterschiedlicher Klassen mit maximalem Abstand voneinander trennt. Hierbei kann eine geeignete Ebene mehr Dimensionen aufweisen als der Merkmalsraum (vgl. \textbf{Abbildung \ref{fig:svm}}). Die gefundene Ebene wird anhand der Vektoren beschrieben, die am nächsten zur Ebene liegen. Diese werden als Support Vektoren bezeichnet. Danach kann ein zu klassifizierendes Objekt (grünes Dreieck) anhand seiner Lage zur aufgespannten Hyperebene eindeutig einer der beiden Klassen zugeordnet werden.

\subsection{Klassifikationsgüte}

Für die Bewertung eines Klassifikators wird eine Bewertungsmetrik benötigt. Als Metrik wird in dieser Arbeit die Klassifikationsgüte verwendet. Die Güte gibt die Genauigkeit einer Klassifikation an und wird als Verhältnis von richtig klassifizierten Objekten zur Gesamtzahl aller klassifizierten Objekte berechnet (vgl. \textbf{Formel \ref{eqn:class}}).

\begin{equation}
\label{eqn:class}
Klassifikationsg\ddot{u}te~=~\frac{\#(richtig~klassifizierter~Objekte)}{\#(zu~klassifizierender~Objekte)}\cdot 100\%
\end{equation}


\subsection{Kreuzvalidierung}

Kreuzvalidierung ist eine Methode zur Klassifikation einer Datenbank und zur Bewertung einer Klassifikationsmethode. Hierbei wird eine bereits vorklassifizierte Menge in möglichst gleichgroße Teilmengen geteilt. Anschließend wird ein Klassifikator mit N-1 dieser N Teilmengen trainiert und eine Nte Teilmenge klassifiziert. Dieses wird so oft wiederholt, bis jede der N Teilmengen einmal klassifiziert wurde. Die Anzahlen der richtig klassifizierten Objekte werden anschließend addiert und durch die Gesamtzahl an Musikstücken der Datenbank geteilt.\\\\
Für die im folgenden Abschnitt angegebenen Klassifikationsgüten wurde die GTZAN Datenbank\cite{gtzan} als Grundlage verwendet. Diese beinhaltet 1000 Musikstücke (á 30 s bei 22050 Hz, 16 bit Sample, mono), die sich zu gleichen Teilen auf die 10 enthaltenen Klassen \textit{blues, classical, country, disco, jazz, metal, pop, punk, reggae} und \textit{rock} verteilen.\\
Für die Kreuzvalidierung werden diese 1000 Lieder in 10 Teilmengen unterteilt, so dass je 10 Lieder pro Klasse in einer Teilmenge vorhanden sind (vgl. \textbf{Tabelle \ref{tab:gtzan}}).

\begin{table}[ht]
	\centering
		\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
		\hline
			Klasse&1&2&3&4&5&6&7&8&9&10\\
		\hline
		\hline
			blues&10&10&10&10&10&10&10&10&10&10\\
		\hline
			$\vdots$&$\vdots$&$\vdots$&$\vdots$&$\vdots$&$\vdots$&$\vdots$&$\vdots$&$\vdots$&$\vdots$&$\vdots$\\
		\hline
			reggae&10&10&10&10&10&10&10&10&10&10\\
		\hline
		\end{tabular}
	\caption{Schema der Teilmengenbildung von GTZAN}
	\label{tab:gtzan}
\end{table}


\section{Musikklassifikationsmethoden}\label{sec:fset}

Für die Laufzeitanalysen sind vier verschiedene Methoden zur Musikklassifikation vorgegeben, die sich im Wesentlichen durch die Merkmalssätze unterscheiden. Alle Methoden verwenden einen SVM-Klassifikator\cite{libsvm} und entweder die RMD-, MSA- oder eine Kombination aus beiden Prozessierungsmethoden. Die Merkmalssätze und Prozessierungsmethoden der jeweils angewandten Musikklassifikationsmethode sind der \textbf{Tabelle \ref{tab:meth}} zu entnehmen. Die mit diesen Methoden erreichten Klassifikationsgüten sind mit der GTZAN Datenbank\cite{gtzan} gemessen.

\begin{table}[ht]
	\centering
		\begin{tabular}{|c|c c|c|c|c|}
		\hline
		Name & Mermalssatz &  & Prozessierungsmethode & Klassifikator & Güte\\
		\hline\hline
		\multirow{4}{*}{MCL1}&SPC & \multirow{4}{*}{FSet1}&\multirow{4}{*}{RMD}&\multirow{4}{*}{SVM}&\multirow{4}{*}{73,4\%}\\
		&SR&&&&\\
		&SF&&&&\\
		&MFCC&&&&\\
		\hline
		\multirow{3}{*}{MCL2}&NASE & \multirow{3}{*}{FSet2}&\multirow{3}{*}{MSA}&\multirow{3}{*}{SVM}&\multirow{4}{*}{78,6\%}\\
		&OSC&&&&\\
		&MFCC&&&&\\
		\hline
		\multirow{3}{*}{MCL3}&LE & \multirow{3}{*}{FSet3}&\multirow{3}{*}{MSA \& RMD}&\multirow{3}{*}{SVM}&\multirow{3}{*}{57,7\%}\\
		&RMS&&&&\\
		&ZCR&&&&\\
		\hline
		\multirow{3}{*}{MCL4}&AOMIC& \multirow{3}{*}{FSet4}&\multirow{3}{*}{MSA \& RMD}&\multirow{3}{*}{SVM}&\multirow{3}{*}{68,1\%}\\
		&SCF&&&&\\
		&SBER&&&&\\
		\hline
		\end{tabular}
	\caption{Übersicht der Musikklassifikationsmethoden}
	\label{tab:meth}
\end{table}

Während die Musikklassifikationsmethoden 1, 3 und 4 mit den Parametern $N=512$ und $Nhop=0$ verarbeitet werden, weist MCL2 zwei Abweichungen auf. Erstens besteht bei MCL2 eine Fensterüberlappung von 50\% was zu $Nhop=256$ führt und zweitens findet bei dieser Musikklassifikationsmethode eine Fensterung nach dem Hamming-Prinzip statt.


