\chapter{Das EVM8168-Entwicklungsboard}
\label{ch:board}
\rm
In diesem Kapitel wird die zugrundeliegende Hardware beschrieben, auf der die Untersuchungen und Optimierungen der folgenden Kapitel durchgeführt werden.\\
Hierfür wird als erstes das EVM8168-Entwicklungsboard der Firma Texas Instruments vorgestellt, auf welchem sich der betrachtete DaVinci\texttrademark-Prozessor befindet. Danach wird der DaVinci\texttrademark-Prozessor näher erläutert. In einer detaillierten Betrachtung werden im Anschluss die beiden im DaVinci\texttrademark-Prozessor integrierten Prozessorkerne (ARM Cortex-A8 und C674x DSP) und ihre zur Verfügung gestellten Hardware-Einheiten vorgestellt. Als letztes wird auf die verwendete Entwicklungsumgebung, dass sogenannte EZSDK der Firma Texas Instruments eingegangen.



\section{Aufbau des EVM8168} \label{sec:evm816}
Für die in den folgenden Kapiteln beschriebenen Arbeitsschritte zur Optimierung und Analyse des Programmes wurde ein EVM8168-Entwicklungsboard verwendet, welches von der Firma Texas Instruments in Zusammenarbeit mit der Firma Spectrum Digital entwickelt wurde.\\
Dieses Board kann mit Hilfe eines DM816x (DaVinci\texttrademark) ARM-Prozessors entweder selber Programme ausführen (oder es können auch die beiden ARM-Prozessoren C6A816x (Integra\texttrademark) oder AM389x (Sitara\texttrademark) emuliert werden).\\ 
Wie in \cite{spec} beschrieben bietet das EVM816x-Entwicklungsboard eine Standalone-Plattform, um Programme für DaVinci\texttrademark-, Integra\texttrademark- oder Sitara\texttrademark-Prozessoren der Firma Texas Instruments zu entwickeln und zu debuggen. Hierfür sind neben dem DaVinci\texttrademark~noch weitere On-Board Peripherie auf dem Board verfügbar.
Das EVM8168-Board hat unter anderem folgende Komponenten integriert:

\begin{itemize}
	\item DM816x- (DaVinci\texttrademark-)ARM Prozessor (\textbf{Kapitel~\ref{sec:davinci}}) mit NEON-Coprozessor (\textbf{Kapitel~\ref{subsubsec:neon}}) und DSP (\textbf{Kapitel~\ref{subsec:dsp}})
	\item 1 GB DDR3-1600 RAM
	\item AC31061-Audiochip
	\item Gigabit Ethernet
	\item HDMI
	\item VGA
	\item USB

\end{itemize}

\textbf{Abbildung~\ref{fig:top_ti816x_evm}} zeigt eine Draufsicht auf das Entwicklungsboard und die unterhalb dessen angebrachte Daughtercard mit weiteren Anschlussmöglichkeiten.

\begin{figure}[htbp]
	\centering
		\includegraphics[scale=0.4]{../Pictures/top_ti816x_evm.png}
	\caption{Draufsicht auf das EVM8168}
	\label{fig:top_ti816x_evm}
\end{figure}



\section{Der DaVinci\texttrademark}\label{sec:davinci}
Bei dem auf dem EVM816x verwendeten ARM-Prozessor DM816x handelt es sich um einen für die Videoprozessierung geeigneten Prozessor der DaVinci\texttrademark-Familie von Texas Instruments.\\
Der DM816x ist ein heterogener Prozessor, der aus mehreren Komponenten besteht.
\textbf{Abbildung \ref{fig:dm8168}} zeigt das vereinfachte funktionale Blockdiagramm des DM816x.\\
%
\begin{figure}[htbp]
	\centering
		\includegraphics[scale=0.5]{../Pictures/dm8168.pdf}
	\caption{Vereinfachtes Funktionales Blockdiagramm des DM816x\cite{evm8168}}
	\label{fig:dm8168}
\end{figure}
%
Neben dem ARM und dem DSP Subsystem, auf die in den folgenden Abschnitten noch näher eingegangen wird, befinden sich noch weitere Komponenten auf dem DM8168. Diese Komponenten werden im Folgenden der Vollständigkeit halber kurz erläutert, haben aber für diese Arbeit keine Relevanz.\\
Der High-Definition Video Image Coprocessor 2 (HDVICP2) bietet einen Hardwarebeschleuniger zum Kodieren und Dekodieren von Videos mit einer Auflösung von bis zu 1080p. Das High-Definition Video Processing Subsystem (HDVPSS) bietet eine Schnittstelle für die Ein- und Ausgabe externer visueller Peripherie, wie zum Beispiel Video Sensoren oder LCD-Bildschirme. Der Media Controller ist für die Verwaltung dieser beiden Komponenten verantwortlich.\\
Des weiteren ist eine SGX530 3D Graphics Engine vorhanden, die für die Berechnung von Vektor- oder 3D-Grafiken verwendet werden kann. Unter dem Begriff System Control sind Elemente wie der Watchdog und der Real-Time Timer und der JTAG-Anschluss zusammen gefasst. All diese Komponenten sind durch eine gemeinsame System Interconnection verbunden. Unter System Interconnection ist hierbei nicht ein einzelner Bus zu verstehen, sondern eine Ansammlung von Bussen verschiedener Breiten und Typen, die der Einfachheit halber zusammengefasst wurden. 

\subsection{ARM Cortex-A8}\label{subsec:a8}

Der erste Prozessor aus der heterogenen Prozessorarchitektur des DM8168 der vorgestellt werden soll, ist ein Cortex-A8 der Firma ARM. Hierbei handelt des sich um einen General-Purpose Prozessor im RISC Design. Er besteht im wesentlichen aus 6 Komponenten (vgl. \textbf{Abbildung \ref{fig:a8}}).
%
\begin{figure}[h]
	\centering
		\includegraphics[width=1\textwidth]{../Pictures/cortexa8.pdf}
	\caption{Vereinfachtes Cortex-A8 Blockdiagramm mit NEON-Coprozessor\cite{cortexa8}}
	\label{fig:a8}
\end{figure} 
%
Die drei Komponenten Instruction fetch, Instruction Decode und Instruction execute sind für das Laden, Dekodieren und Ausführen von Befehlen auf dem ARM Cortex-A8 zuständig und bilden mit der Load/Store-Komponente eine Ausführungseinheit, die auf der ARMv7-A Architektur basiert.\\
Der ARMv7-A Instruktionssatz besitzt neben Operationen für Sprünge und Ähnlichem nur Operationen für die Berechnung von Integerwerten.\\
Die wesentlichen Merkmale der L1 und L2-Caches sind in \textbf{Tabelle \ref{tab:cache}} zusammengefasst.

\begin{table*}[ht]
	\centering
		\begin{tabular}{|c|c|c|}
		\hline
			& L1-Caches & L2 Cache\\
		\hline\hline
			Größe & 32 KB & 256 KB\\
			Zeilenlänge & 64 Bytes & 64 Bytes\\
			Cachestruktur & 4-fach assoziativ & 8-fach assoziativ\\
		\hline
		\end{tabular}
	\caption{Wesentliche Merkmale der L1- und L2-Caches des Cortex A8\cite{evm8168}}
	\label{tab:cache}
\end{table*}

Instruktionen werden in einer dreiphasigen Pipeline verarbeitet, die in 13 Stufen unterteilt ist. Hierbei wird jede Phase von der gleichnamigen Einheit aus \textbf{Abbilgund \ref{fig:a8}} bearbeitet.\\
Die Fetch-Phase besitzt drei Stufen. In ihr werden benötigte Befehle aus dem L1-Instruction-Cache geladen, der sich in der Instruction Fetch-Einheit befindet (vgl. \textbf{Abbildung \ref{fig:a8}}).\\
Diese Instruktionen werden in einen Buffer geladen, welcher in der fünfstufigen Decode-Phase ausgelesen wird und die Instruktionen decodiert werden. Außerdem wird in der Decode-Phase die Ausführungsreihenfolge der geladenen Befehle festgelegt. Diese Reihenfolge hängt von Datenabhängigkeiten und Ausführungszeiten der einzelnen Operationen ab (eine Übersicht der Instruktionen wird im Anhang gegeben).\\
In der Execute-Phase werden anschließend die Befehle an die entsprechenden Funktionseinheiten weitergeleitet. Dieses geschieht in sechs Stufen.\\
Die Execute-Einheit unterstützt keine Floating Point Instruktionen. Diese werden stattdessen emuliert. Derartige Floating Point Instruktionen sind durch das Präfix \textit{\_\_aeabi\_} im Assembler-Code gekennzeichnet. Dies bedeutet, dass Floating Point-Operationen nicht auf Hardware-, sondern auf Softwareebene berechnet werden, was zu langen Ausführungszeiten führt.\\
Die \textbf{Tabelle \ref{tab:aeabi}} listet wesentliche Bezeichnungen der in Software emulierten Floating Point-Operationen auf.\\
%
\begin{table}[h]
\centering
\begin{tabular}{|c|c|}
\hline
Befehl & Beschreibung\\
\hline\hline
float \_\_aeabi\_fadd(float a, float b) & single-precision Addition\\
float \_\_aeabi\_fdiv(float n, float d) & single-precision Division, n/d\\
float \_\_aeabi\_fmul(float a, float b) & single-precision Multiplikation\\
float \_\_aeabi\_frsub(float x, float y) & single-precision umgekehrte Subtraktion, y - x\\
float \_\_aeabi\_fsub(float x, float y) & single-precision Subtraktion, x - y\\
int \_\_aeabi\_fcmpeq(float a, float b) & 1, wenn a = b\\
int \_\_aeabi\_fcmplt(float a, float b) & 1, wenn a < b\\
int \_\_aeabi\_fcmple(float a, float b) & 1, wenn a <= b\\
int \_\_aeabi\_fcmpge(float a, float b) & 1, wenn a >= b\\
int \_\_aeabi\_fcmpgt(float a, float b) & 1, wenn a > b\\
\hline
\end{tabular}
\caption{Auszug der Floating Point-Operationen des ARMv7\cite{aeabi}}
\label{tab:aeabi}
\end{table}
%
Der Instruktionssatz besitzt des weiteren Operationen für die Kommunikation mit anderen Coprozessoren. Diese Befehle werden mit MCR und MRC bezeichnet und besitzen Ausführungszeiten, die vom angesprochenen Coprozessor abhängen. Zum Beispiel benötigt eine Kommunikation mit der System Control aus \textbf{Abbildung \ref{fig:dm8168}} 60 Takte.

\subsubsection{Der NEON-Coprozessor}\label{subsubsec:neon}
Dieser Coprozessor beherbergt zwei Einheiten zur Berechnung von Floating Point-Operationen. Zum einen ist das die VFPv3-Einheit (\textbf{\ref{ph:vfp}}) und zum anderen die NEON-SIMD-Einheit (\textbf{\ref{ph:neon}}). 
%
\begin{figure}[h]
	\centering
		\includegraphics[scale=0.8]{../Pictures/NEON.pdf}
	\caption{Vereinfachtes Blockdiagramm des NEON-Coprozessors}
	\label{fig:neon}
\end{figure} 
%

Wie in \textbf{Abbildung \ref{fig:neon}} zu sehen ist, besteht der NEON-Coprozessor im Wesentlichen aus fünf Komponenten. Außerdem besitzt dieser zwei Eingangsqueues. In die erste Eingangsqueue werden die vom ARM vorbereiteten NEON-SIMD- oder VPFv3-Befehle geschrieben, diese Queue kann bis zu 16 Einträge halten und wird als \textit{NEON Instruction Queue} bezeichnet. Die zweite Queue ist für das Vorladen von Daten aus dem L1- oder L2-Cache verantwortlich, diese kann 12 Einträge halten und wird als \textit{NEON Data Queue} bezeichnet. Diese Queue wird von der Load/Store-Einheit ausgelesen oder beschrieben.\\
Die in der NEON Instruction Queue befindlichen Daten werden vor der Ausführung auf dem NEON-Coprozessor nochmal mit einer eigenen Instruction Decode-Einheit dekodiert, wobei auch VFPv3- und NEON-SIMD-Befehle voneinander getrennt und anschließend entweder an die NEON-SIMD-Pipeline oder die VFPv3-Einheit weitergeleitet werden. Hierbei ist zu Erwähnen, dass immer nur eine dieser beiden Einheiten arbeiten kann, eine Verarbeitung von NEON-SIMD- und VFPv3-Befehlen parallel also nicht möglich ist.\\
Des weiteren besitzt der NEON-Coprozessor eine physikalische Registerbank, die in 32x64-bit Registerfiles unterteilt ist. Sowohl VFPv3-Einheit als auch die NEON-SIMD-Pipeline haben Zugriff auf diese. Für diese Registerbank sind drei verschiedene Namensgebungen vorhanden, die im Assembler-Code verwendet werden können. Diese Namensgebungen bezeichnen die Wortbreite, mit der aus den Registern gelesen werden kann. Es ist möglich mit einfacher (S-Namensgebung), doppelter (D-Namensgebung) und vierfacher (Q-Namensgebung) Wortbreite aus diesem Register zu lesen. Bei einfacher Wortbreite ist allerdings nur das halbe Register zugreifbar.\\
Die Kommunikation zwischen ARM und NEON-Einheit lässt sich in zwei Teile unterteilen:
\begin{itemize}
\item Weiterleitung von Befehlen
\item Weiterleitung von Daten
\end{itemize}

Die Weiterleitung von Befehlen vom ARM zum NEON-Coprozessor geschieht in folgenden Schritten:

\begin{enumerate}
\item NEON-SIMD- und VFPv3-Befehle durchlaufen die gesamte ARM-Pipeline und werden am Ende der Execute-Phase in eine NEON Instruction Queue geladen. Danach gelten die NEON-SIMD- und VFPv3-Befehle für den ARM als verarbeitet, so dass dieser weitere Befehle ausführen kann. Eine Ausnahme bildet hier der Fall, dass die NEON Instruction Queue voll ist. In diesem Fall muss der ARM warten bis weitere Befehle in die Instruction Queue geschrieben werden können.
\item Der NEON-Coprozessor ließt dieser Queue aus und dekodiert die Befehle nochmals.
\item Die NEON-SIMD- und VFPv3-Befehle werden auf dem NEON-Coprozessor verarbeitet
\item Mit dem MRC-Befehl ließt der ARM die Ergebnisse des NEON-Coprozessors aus. Dieses dauert mindestens 20 Takte
\end{enumerate}

Die Weiterleitung von Daten an den NEON-Coprozessor kann auf zwei Arten geschehen:

\begin{itemize}
\item Der ARM Prozessor schreibt mit dem MCR-Befehl Daten aus dem L1-Cache seiner Load/Store-Einheit in die NEON Daten Queue
\item oder der NEON-Coprozessor ließt direkt aus dem L2 Cache.
\end{itemize}

Obwohl sich die NEON-SIMD-Pipeline und VFPv3-Einheit einige Befehle und die Registerbank teilen, haben sie doch entscheidende Unterschiede, die in den beiden folgenden Kapiteln erläutert werden sollen.

\paragraph{VFPv3-Einheit}\label{ph:vfp}$\;$ \\\\
Die VFPv3-Einheit beschleunigt die Berechnung von Floating Point-Zahlen und unterstützt den \textit{ANSI/IEEE Standard 754-1985} in vollem Umfang.\\
Operationen wie Addition, Subtraktion, Multiplikation, Division, Multiply-and-Accumulate und zur Wurzelberechnung können daher mit Single-Precision und mit Double-Precision berechnet werden. Des weiteren werden Operationen zur Konvertierung zwischen Floating- und Fix-Point und Floating-Point und Konstanten bereitgestellt.\\
Die VFPv3-Einheit besitzt keine Pipeline-Struktur und verarbeitet Anweisungen sequentiell.\\
Sie kann auf die in \textbf{Abbildung \ref{fig:neon}} abgebildete Registerbank mit einfacher und doppelter Wortbreite(S- und D-Namensgebung) zugreifen.

In \textbf{Tabelle \ref{tab:vfp}} sind wesentliche Instruktionen aus dem Instruktionssatz der VFPv3-Einheit mit Angabe der Ausführungszeit in Takten angegeben. Hierbei sind diese Ausführungszeiten datenabhängig.

\begin{table}
\centering
\begin{tabular}{|c|c|c|}
\hline
Befehl & Single-Precision-Takte & Double-Precision-Takte\\
\hline\hline
FADD & 9-10 & 9-10\\
FSUB & 9-10 &9-10\\
FMUL \& FNMUL & 10-12 & 11-17\\
FMAC \& FNMAC & 18-21 & 19-26\\
FDIV & 20-37 & 29-65\\
FSQRT & 19-33 & 29-60\\
FABS & 4 & 4\\
FCMP & 4 oder 7 & 4 oder 7\\
FCPY & 4 & 4\\
\hline
\end{tabular}
\caption{Auszug aus dem Instruktionssatz der VFPv3-Einheit\cite{cortexa8}}
\label{tab:vfp}
\end{table}

\paragraph{NEON-SIMD-Einheit}\label{ph:neon}$\;$ \\\\
Diese Einheit basiert auf der \textit{Advanced SIMD Media Processing-Architektur}. SIMD steht hierbei für \textit{Single Input Multiple Data} und heißt, dass ein und derselbe Befehl gleichzeitig auf mehrere Daten angewendet werden kann. Bei Floating Point Berechnungen kann sie 128 Bit pro Operand lesen und schreiben. Allerdings ist es nur möglich 64 Bit pro Operand gleichzeitig zu verarbeiten, daher werden Operationen auf vierfacher Wortbreite in zwei Schritten abgearbeitet. Im ersten Schritt werden die Least Significant Bits (LSBs) der Operanden gelesen und miteinander verrechnet, im zweiten Schritt die Most Significant Bits (MSBs). Solche Operationen benötigen 2 Takte. daraus folgt, dass es der NEON-SIMD-Einheit möglich ist zwei Operationen parallel auszuführen.
Auch die NEON-SIMD-Einheit verwendet die in \textbf{Abbildung \ref{fig:neon}} abgebildete Registerbank und kann Operationen auf dieser entweder mit doppelter oder vierfacher Wortbreite (D- oder Q-Namensgebung) verarbeiten.\\
Die Einheit kann bis zu zwei Advanced SIMD Operationen pro Takt empfangen.\\
Des weiteren werden NEON-SIMD-Befehle in einer 10-stufigen Pipeline verarbeitet.\\
Außerdem ist es der NEON-SIMD-Einheit möglich, Teile der VFPv3-Befehle in ihrer Pipeline auszuführen, um die Verarbeitungszeit zu beschleunigen.\\
In \textbf{Tabelle \ref{tab:neon}} ist ein Auszug des NEON-SIMD-Befehlssatzes mit Ausführungszeiten in  Takten angegeben. Single-Precision-Befehle werden im Assemblercode durch den Zusatz \textit{.f32} hinter dem Befehlsnamen gekennzeichnet.

\begin{table}[hpt]
\centering
\begin{tabular}{|c|c|c|}
\hline
Befehl & Takte\\
\hline\hline
VADD & 1-2\\
VSUB & 1-2\\
VMUL & 1-2\\
VABS & 1-2\\
VRSQRT&1-2\\
VMLA&1-2\\
VMLS&1-2\\
VMOV & 1\\
VLDR  & 1-2\\
VSTR  & 1-2\\
\hline
\end{tabular}
\caption{Auszug aus dem Floating Point-Befehlssatz der NEON-SIMD-Einheit\cite{cortexa8}}
\label{tab:neon}
\end{table}

\subsection{Der C674x-DSP-Prozessor}\label{subsec:dsp}
Der C674x-DSP der Firma Texas Instruments gehört zur C6000-Familie und ist ein VLIW DSP mit Floating Point-Hardware. \textbf{Abbildung \ref{fig:DSPblock}} zeigt das Blockdiagramm des DSPs.
%
\begin{figure}[h]
	\centering
		\includegraphics[width=1\textwidth]{../Pictures/DSPblock.pdf}
	\caption{Vereinfachtes C674x Blockdiagramm\cite{evm8168}}
	\label{fig:DSPblock}
\end{figure} 
%

Im Wesentlichen besteht der C674x aus vier Komponenten. Die erste Komponente ist die C674x+ CPU in der Befehle des C674x-Instuktionssatz verarbeitet werden. Neben dieser bestehen getrennte L1-Befehls- (L1P) und Datencaches (L1D) und ein L2-Cache. Dem L1D-Cache ist es bei Bedarf möglich mit 8x32bit-Datenleitungen auf das L1D-RAM zuzugreifen. In \textbf{Tabelle \ref{tab:dspcache}} sind die wesentlichen Merkmale der verwendeten Caches angegeben.

\begin{table*}[ht]
	\centering
		\begin{tabular}{|c|c|c|c|}
		\hline
			& L1P-Caches & L1D-Cache & L2 Cache\\
		\hline\hline
			Größe & 32KB & 32 KB & 256 KB\\
			Zeilenlänge & 32 Bytes & 64 Bytes & 128 Bytes\\
			Cachestruktur & Direct-mapped& 2-fach assoziativ & 4-fach assoziativ\\
		\hline
		\end{tabular}
	\caption{Wesentliche Merkmale der L1- und L2-Caches des C674x DSP\cite{sprug82a}}
	\label{tab:dspcache}
\end{table*}


Die Registerarchitektur innerhalb der C674x+ CPU, ihr Instruktionssatz und die Pipelinestruktur wird im Nachfolgenden näher erläutert.

\paragraph{Registerarchitektur und Instruktionssatz}\label{ph:reginst}$\;$ \\\\
Wie ebenfalls in \textbf{Abbildung \ref{fig:DSPblock}} zu sehen ist, besitzt die C674x+ CPU zwei parallele Datenpfade, die mit Register File A und B bezeichnet sind. Beide Datenpfade sind mit je mit einer 64 Bit breiten Anbindung an den L1D-Cache angeschlossen, können also parallel 64 Bit lesen oder schreiben.\\
Innerhalb dieser Datenpfade befinden sich acht Ausführungseinheiten zur Bearbeitung von Befehlen, je vier pro Datenpfad. Jeder Ausführungseinheit ist hierbei ein Teil des Instruktionssatzes zugeordnet.\\
Daraus folgt, dass im Idealfall parallel acht Befehle pro Takt ausgeführt werden können.\\
In \textbf{Abbildung \ref{fig:DSPblock}} ist der Aufbau der beiden Datenpfade Register File A und B zusehen. Nicht eingezeichnet sind die beiden sogenannten Crosspaths, die es Operationen aus dem Datenpfad A erlauben, ein Datum pro Takt aus Register File B zu lesen und umgekehrt. Insgesamt besitzt der DSP 64 32 Bit-Register, je 32 in A und B.
Auch wenn einige Instruktionen auf mehreren Ausführungseinheiten ausgeführt werden können, lässt sich eine grobe Zuordnung von Instruktionen zu Ausführungseinheiten feststellen: 
\begin{itemize}
\item .M führt Multiplikationen aus
\item .L und .S sind für alle anderen arithmetischen Operationen zuständig
\item .D ist für das Laden und Speichern von Daten verantwortlich. 
\end{itemize}
\textbf{Tabelle \ref{tab:c674x}} gibt einen Überlick über wesentliche Befehle mit Angaben über die zugeordneten Ausführungseinheiten, Anzahl erforderlicher Takte zur Ausführung, sowie der Anzahl an Functional Unit Latency (FUL) und Delayslots, welche fürs Pipelining wichtig sind. Hierbei gibt die Functional Unit Latency die Anzahl an Takten an, die eine Einheit nach Abschluss einer Berechnung benötigt, bis sie eine neue Berechnung annehmen kann. Die Delayslots geben die Takte an, die zwischen Einlesen der Operanden und dem Abschluss der Berechnung vergehen. Die maximale Anzahl an Delayslots beträgt neun. Der Instruktionssatz besitzt keine Befehle für Divisionen oder Wurzeloperationen. Diese werden nach dem Newton-Raphson-Verfahren in Software berechnet. Hierfür steht die reziproke Wurzel als Instruktion zur Verfügung, die zur Berechnung der Wurzel erforderlich ist.

\begin{table}[ht]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
Befehl & Gruppe & Takte & Delayslots & FUL\\
\hline\hline
ADD & .D,.L\&.S & 1 & 0 & 0\\
ADDSP & .L\&.S & 4 & 3 & 1\\
ADDDP & .L\&.S & 7 & 6 & 2\\
LDW & .D & 5 & 4 & 0\\
MPY & .M & 2 & 1 & 0\\
MPYSP & .M & 4 & 3 & 1\\
MPYSPDP & .M & 7 & 6 & 3\\
MPYSP2DP & .M & 5 & 4 & 2\\
MPYDP & .M & 10 & 9 & 4\\
RSQRSP & .S & 1 & 0 & 1\\
RSQRDP & .S & 2 & 1 & 1\\
SUB & .D,.L\&.S & 1 & 0 & 0\\
SUBSP & .L\&.S & 4 & 3 & 1\\
SUBDP & .L\&.S & 7 & 6 & 2\\
\hline
\end{tabular}
\caption{Auszug aus dem Instruktionssatzssatz des C674x\cite{sprufe8b}}
\label{tab:c674x}
\end{table}

\paragraph{Pipelining auf dem C674x}\label{ph:dsppipe}$\;$ \\\\
Die Pipeline des C674x lässt sich in drei Phasen unterteilen:

\begin{enumerate}
\item Fetch
\item Decode
\item Execute
\end{enumerate}

Die Fetch-Phase besitzt vier Stufen, die Decode-Phase zwei Stufen und die Execute-Phase maximal 10 Stufen, hierbei ist eine Stufe immer einen Takt lang.

\subparagraph{Die Fetch-Phase}\label{subph:fetch}$\;$ \\\\
In der Fetch-Phase werden in vier Stufen Instruktionen aus dem Instruktionscache geladen. Instruktionen werden hierfür zu Fetch Paketen (FP) zusammengefasst, welche aus acht Instruktionen bestehen.

\subparagraph{Die Decode-Phase}$\;$ \\\\
Die Decode-Phase besteht aus zwei Stufen:
\begin{enumerate}
\item DP: Instruction dispatch
\item DC: Instruction decode
\end{enumerate}

In der DP-Stufe wird das zuvor geladene Fetch Paket in sogenannte Execute Pakete zerlegt. Ein Execute Paket enthält parallel auszuführende Instruktionen. Ein Execute Paket besteht immer mindestens aus einem und maximal aus acht Instruktionen. Außerdem werden in dieser Stufe jeder Instruktion eines Execute Pakets eine geeignete Ausführungseinheit zugeordnet. Hierbei muss beachtet werden, dass Ausführungseinheiten noch auf Grund von Latenzen belegt sein können (siehe \textbf{\ref{ph:reginst}}). Operationen die parallel bearbeitet werden sind im späteren Assembler-Code mit einem \glqq ||\grqq\  gekennzeichnet.\\
Während der DC-Stufe werden die Quell- und Zielregister und gegebenenfalls zugewiesene Crosspaths dekodiert, welche bei der späteren Ausführung benötigt werden. 

\subparagraph{Die Execute-Phase}$\;$ \\\\
In der Execute-Phase werden die vorher geladenen und decodierten Befehle auf den Hardwareeinheiten ausgeführt. Diese Stufe wird  in zehn Stufen (E1-E10) unterteilt. Die Anzahl durchzulaufender Stufen ist durch instruktionsbezogene Delayslots spezifiziert.

%\subparagraph*{Die Execute-Phase bei Double-Precision}$\;$ \\\\
%Durch die Besonderheit von Double-Precision-Funktionen Operanden und Ergebnisse in zwei Schritten zu lesen, bzw. zu schreiben, ergeben sich Möglichkeiten dieses beim Scheduling solcher Funktionen auszunutzen. Hierbei werden immer erst die LSBs gelesen, bzw. geschrieben und einen Takt später die MSBs.\\
%Soll zum Beispiel erst eine Multiplikation (MPYSP2DP) und danach eine Addition (ADDDP) dieses Ergebnisses mit einem andern Wert geschehen, so kann die Addition bereits in dem Takt mit der Bearbeitung anfangen, in dem das LSB des Ergebnisses der Multiplikation geschrieben wurde.

\subsubsection{Code Parallelisierung durch Software Pipelined Loop (SPLOOP)}\label{ph:sploop}
SPLOOP ist ein Konzept zur parallelen Verarbeitung von Schleifen-Iterationen. Hierbei werden Instruktionen der verschiedenen Iterationen gleichzeitig verarbeitet. Dieses Konzept lässt sich vollständig durch eine Unterstürzung des Compilers realisieren. Hierfür wird während der Kompilierung ein Ausführungsplan aufgestellt, wobei ein Iterationsschritt in sogenannte Stages unterteilt wird. Eine Stage bezeichnet einen Teil des sequentiell auszuführenden Codes eines Iterationsschritts, der eine vorgegebene Ausführungszeit in Takten besitzt und mit anderen Stages parallel verarbeitet werden kann. Diese Ausführungszeit wird als Iterationsintervall bezeichnet.\\
Die schematische Verarbeitung der Stages ist in \textbf{Abbildung \ref{fig:sploop}} dargestellt.
%
\begin{figure}[htb]
	\centering
		\includegraphics[width=1\textwidth]{../Pictures/sploop.pdf}
	\caption{Software Pipelined Execution Flow\cite{sprufe8b}}
	\label{fig:sploop}
\end{figure} 
%
Die Phase bis alle Stages parallel verarbeitet werden wird als Prolog bezeichnet. Nach dem Prolog folgt der Kernel, der die Phase bezeichnet, in der alle Stages parallel verarbeitet werden. Auf den Kernel folgt der Epilog. Prolog und Epilog sind $\#Stages - 1$ lang.\\ 
Der C674x besitzt eine hardwareseitige Unterstützung für SPLOOPs. Hierbei werden die Execution Pakete der SPLOOP in einen speziellen Buffer geladen. Durch zusätzliche Logik werden anschließend die Execute Pakete der verschiedenen Stages parallel ausgeführt. Die Hardware-Unterstützung bietet folgende Vorteile:

\begin{itemize}
\item Execute Pakete können ohne erneutes fetching aus dem SPLOOP-Buffer geladen werden
\item Die Planung der Verabeitungsreihenfolge wird von der Hardware übernommen
\end{itemize}

Die Berechnung der Gesammtlaufzeit einer Schleife mit SPLOOP wird nach \textbf{Formel \ref{eqn:sploop}} berechnet.

\begin{equation}\label{eqn:sploop}
Zeit~=~ \left(\overbrace{\#Stages-1}^{Prolog}+\overbrace{\#Durchl"aufe}^{Kernel}+\overbrace{\#Stages-1}^{Epilog}\right) \cdot Iterationsinterval
\end{equation}

\paragraph{Beispiel des Software-Pipelinings (SPLOOP)}\label{ph:bspsploop}$\;$ \\\\
Die Funktionsweise von SPLOOP soll nachfolgend am Beispiel der Schleife innerhalb der Berechnung des \textit{Spectral Centroids} erläutert werden. \textbf{Listing \ref{code:scc}} zeigt den C-Code dieser Schleife und \textbf{Listing \ref{code:scasm}} den entsprechenden Assembler-Code.

\begin{lstlisting}[caption=C-Code der Schleife des Spectral Centroids, label=code:scc]
	for (k = 0; k < scsize; ++k) {
		weighted += A[k] * ((realv) k);
		total += A[k];
	}
\end{lstlisting}

\begin{lstlisting}[caption=Assembler-Code der Schleife des Spectral Centroids, label=code:scasm]
;** --------------------------------------------------------------------------*
$C$L1:    ; PIPED LOOP PROLOG

           SPLOOPD 4       ;12               ; (P) 
||         MV      .L1     A4,A6
||         MV      .S1X    B7,A8
||         MVC     .S2     B5,ILC

;** --------------------------------------------------------------------------*
$C$L2:    ; PIPED LOOP KERNEL

           INTSP   .L1     A8,A4             ; |2| (P) <0,0> 
||         LDW     .D1T1   *A6++,A5          ; |2| (P) <0,0> 

           NOP             2
           ADD     .S1     1,A8,A8           ; |1| (P) <0,3> Define a twin register
           NOP             1

           ADDSP   .L2X    A5,B4,B4          ; |3| (P) <0,5>  ^ 
||         MPYSP   .M1     A5,A4,A3          ; |2| (P) <0,5> 

           NOP             2
           NOP             1
	
           SPKERNEL 1,2
||         ADDSP   .L1     A3,A7,A7          ; |2| <0,9>  ^ 

;** --------------------------------------------------------------------------*
$C$L3:    ; PIPED LOOP EPILOG
;** --------------------------------------------------------------------------*
\end{lstlisting}
Ein || am Anfang einer Zeile bedeutet, dass der folgende Befehl parallel zum Befehl der vorherigen Zeile ausgeführt wird. So werden z.B. \textit{INTSP} und \textit{LDW} parallel ausgeführt.\\
Wie durch den Befehl \textit{SPLOOPD 4} angegeben ist, beträgt die Länge eines Iterationsintervals respektive einer Stage vier Takte. Des weiteren sind sechs Stages vorhanden, welche innerhalb des Codes durch Leerzeilen getrennt sind. Die einzige Ausnahme ist der Befehl \textit{LDW}. Dieser wird in fünf Takten ausgeführt, jedoch wird das Ergebnis erst von der übernächsten Stage weiter verarbeitet, so dass keine Daten-Konflikte auftreten. Der Befehl \textit{SPKERNEL} markiert das Ende des Kernels. Die Argumente dieses Befehls geben an, wie lange nach dem letzten Durchlauf gewartet werden muss, bis wieder Operationen ausgeführt werden können. In diesem Fall muss die Laufzeit einer Stage und zusätzliche 2 Takte gewartet werden, also insgesamt 6 Takte.\\
Die Konstante \textit{scsize} aus \textbf{Listing \ref{code:scc}} steht für die Anzahl an Betragsspektren eines Audio-Fensters.\\
Im Fall des \textit{Spectral Centroids} mit einer Fensterbreite von 512, beträgt die Gesamtlaufzeit 1064 Takte.

\section{Linux EZ Software Development Kit (EZSDK)}\label{sec:ezsdk}
Das Linux EZ Software Development Kit (EZSDK) ist eine von Texas Instruments zum EVM816x-Board mitgelieferte Sammlung von wichtigen und nützlichen Tools. Das EZSDK (gesprochen: \textit{EasySDK}) teil sich in zwei Bereiche, zum einen in Tools für den ARM Cortex A8 und zum anderen in Tools für den C674x DSP (vgl. \textbf{Abbildung \ref{fig:ezsdk}}).
%
\begin{figure}[htb]
	\centering
		\includegraphics[width=1\textwidth]{../Pictures/EZSDK.pdf}
	\caption{Struktureller Aufbau des EZSDK}
	\label{fig:ezsdk}
\end{figure} 
%
Die Tools für den Cortex A8 beinhalten unter anderem das embedded Linux, welches auf dem Prozessor läuft, in der Version 2.6.37, den Bootloader U-Boot und die Code Sourcey Toolchain mit den ARM-Compilern.\\
Für den C674x sind unter anderem das Betriebssystem (SYSBIOS), das Kommunikationsframework C6EZRun inklusive des DSP-Compilers, sowie die optimierten Bibliotheken DSPLIB und MATHLIB vorhanden.

Für diese Arbeit wird die EZSDK-Version 5.02 verwendet.

\subsection{Optimierte Bibliotheken für den C674x}\label{subsubsec:optbib}
Texas Instruments bietet zu den DSPs der C6000-Reihe verschiedene Bibliotheken mit architekturspezifisch optimierten Algorithmen an. Einige dieser optimierten Bibliotheken sind im Umfang des EZSDK (siehe \textbf{Kapitel \ref{sec:ezsdk}}) enthalten. Im Folgenden werden die DSPLIB  und zum anderen die MATHLIB vorgestellt.

\subsubsection{DSPLIB}
Die DSPLIB beinhaltet Algorithmen aus der Signalverarbeitung. Unter anderem ist auch eine Mixed-Radix FFT vorhanden. Die Algorithmen liegen sowohl in C- als auch in Assembler-Code vor.

\subsubsection{MATHLIB}

Die MATHLIB beinhaltet mathematische Funktionen, die ebenfalls in C- und Assembler-Code vorliegen. Die mathematischen Funktionen sind sowohl für Single- als auch Double-Precision vorhanden und sind für skalare und Vektor-Daten ausgelegt.

\subsection{Floating Point Berechnung mit der CodeSourcery-Toolchain}

Die Wahl der Einheit zur Floating Point Berechnung wird während der Kompilierung durch Compiler-Flags getätigt (vgl. \textbf{Tabelle \ref{tab:flags}}).

\begin{table}[ht]
\centering
\begin{tabular}{|c|c|}
\hline
Konfiguration & Flag\\
\hline\hline
ARM & -\\
VFPv3 & -mpfu=vfp\\
NEON & -mfpu=neon\\
\hline
\end{tabular}
\caption{Complier-Flags zur Wahl der Floating Point Berechnung}
\label{tab:flags}
\end{table}
 
Wird bei der Kompilierung nicht spezifiziert, wie Floating Point-Operationen behandelt werden sollen, werden diese immer mit den in \textbf{Tabelle \ref{tab:aeabi}} angegeben Softwarefunktionen emuliert.\\
Sollen solche Operationen auf der VFPv3-Einheit ausgeführt werden muss lediglich das Flag \textit{\-mfpu=vfp} gesetzt werden.\\
Einbindung von NEON-SIMD-Instruktionen in den Programm-Code kann auf drei Wegen erfolgen. Es ist dem Compiler möglich, selber Stellen des Programm-Codes zu identifizieren, die durch die NEON-SIMD-Einheit beschleunigt werden können. \textbf{Listing \ref{code:spfc}} und \textbf{Listing \ref{code:spfneon}} zeigen ein Beispiel, in dem die Multiplikation durch NEON-SIMD-Assembler parallelisiert wird.
\newpage 
\begin{lstlisting}[caption=1. einfaches Beispiel in C, label=code:spfc]
 int i;
 for (i = 0; i < 200; i++) {
 z[i] = a[i] * b[i];
 }
\end{lstlisting}
\begin{lstlisting}[caption=ARM+NEON-Assembler, label=code:spfneon]
	MOV      r3,#0x19 		;nur noch 25 Iterationen;
|L1.4|
	VLD1.16  {d0,d1},[r0]!	;Laden von a;
	SUBS     r3,r3,#1
	VLD1.16  {d2,d3},[r1]!  ;Laden von b;
	VMUL.I16 q0,q0,q1		;a*b;
	VST1.16  {d0,d1},[r2]!	;Speichern in z;
	BNE      |L1.4|
	BX       lr
\end{lstlisting}

Dieses hat den Vorteil, dass keine umständlichen Änderungen am Programm-Code vorgenommen werden müssen. Allerdings ist diese Erkennung von der Struktur des Programm-Codes abhängig. Kommen verschachtelte Schleifen oder Funktionsaufrufe in Schleifen vor, werden diese nicht parallelisiert. In solchen Fällen kann der Compiler mit Umstellung des Programm-Codes unterstützt werden. Wenn die Schleifendurchläufe allerdings variable sind, hat der Compiler damit immer noch Schwierigkeiten.\\
In diesem Fall ist der Einsatz von  NEON-Intrinsics im Programm-Code sinnvoll. Hierbei werden Berechnungen durch entsprechende NEON-Intrinsics ersetzt. \textbf{Listing \ref{code:firstc}} - \textbf{\ref{code:firstneon}} zeigen ein Beispiel, in dem die Addition innerhalb der Schleife durch NEON-Intrinsics für vier parallele Addtitionen ersetzt sind.
\begin{lstlisting}[caption=2. einfaches Beispiel in C, label=code:firstc]
	int i;
 	for(i=0;i<200;i++) {
 	z[i] = x[i] + y[i];
 	}
\end{lstlisting}

\begin{lstlisting}[caption=2. einfaches Beipiel mit Intrinsics, label=code:firstcv]
	int i;
	uint32x4_t x4,y4; // Hier werden 128 bit Register definiert, die die Operanten halten 
	uint32x4_t z4;    // Hier wird ein 128 bit Register definiert, dass das Ergebnis hält 
	uint32_t *ptra = x; //x,y und z sind die Eingangs-, bzw. Ausgangsarrays 
	uint32_t *ptrb = y; 
	uint32_t *ptrz = z; 

	for(i=0; i < 200/4; i++)
	{
        x4 = vld1q_u32(ptra);  // Intrinsic um x4 mit 4 Werten von x zu laden
        y4 = vld1q_u32(ptrb);  // Intrinsic um y4 zu laden
        z4=vaddq_u32(x4,y4);   // Intrinsic um z4=x4+y4 zu addieren
        vst1q_u32(ptrz, z4);   // Speicher die 4 Ergebnisse in z
        ptra+=4; // Pointer inkrementieren
        ptrb+=4;
        ptrz+=4;
	}
\end{lstlisting}
\newpage
\begin{lstlisting}[caption=ARM+NEON-Assembler, label=code:firstneon]
        add      r3, r1, #800
.L2:
        vld1.32  {d4-d5}, [r1] ;Zeile 10;
        add      r1, r1, #16
        vld1.32  {d6-d7}, [r0] ;Zeile 11;
        cmp      r1, r3
        vadd.i32 q3, q3, q2    ;Zeile 12;
        vst1.32  {d6-d7}, [r2] ;Zeile 13;
        add      r0, r0, #16
        add      r2, r2, #16
        bne      .L2
        bx       lr
\end{lstlisting}

Dies bieten den Vorteil, dass Schleifen parallelisiert werden können und der Datenfluss definiert werden kann. Allerdings wird ein Overhead durch Lade und Speicheroperationen erzeugt.\\
Um diesen Overhead zu vermeiden, gibt es noch die Möglichkeit den NEON-SIMD-Assembler per Hand zu schreiben. Hierbei werden sowohl Parallelisierung als auch Datenfluss per Hand bestimmt und Lade-, bzw. Speicheroperationen minimiert. Allerdings besitzt diese Variante auch den größten Aufwand.\\
Für jede dieser Varianten muss das NEON-Compilerflag aus \textbf{Tabelle \ref{tab:flags}} gesetzt sein.

\section{C6EZRun}\label{sec:c6run}

C6EZRun ist ein Framework zur Kommunikation zwischen ARM und DSP.
Hierbei werden zwei unterschiedliche Versionen zur Kommunikation zwischen ARM und DSP angeboten:

\begin{itemize}
\item C6Runlib
\item C6Runapp
\end{itemize}

Außerdem stellt C6EZRun geeignete Compiler für diese beiden Versionen bereit.\\
Bei C6Runlib wird DSP-spezifischer Programm-Code durch Funktionsaufrufe im ARM-Programm ausgeführt. Dies bedeutet, dass der ARM erst nach Ende der DSP-Programm-Code Ausführung mit der eigenen Ausführung fortfahren kann. \textbf{Abbildung \ref{fig:c6lib}} verdeutlicht dieses Prinzip.\\
%
\begin{figure}[htb]
	\centering
		\includegraphics[scale=1]{../Pictures/c6lib.pdf}
	\caption{Prinzip von C6Runlib\cite{c6run}}
	\label{fig:c6lib}
\end{figure} 
%
Unter normalen Umständen besteht keine Möglichkeit vom embedded Linux des ARM Programme auf dem DSP auszuführen. Die Ausführung von Programmen auf dem DSP ist nur embedded möglich. Mit Hilfe von C6Runapp können C-Programme jedoch von der Linux-Console des ARM aufgerufen werden. Der ARM fungiert hierbei als Initiator und CIO-Server. Auf diese Weise ist es DSP-Programmen möglich, Ausgaben über die Console des ARM zu tätigen und ebenfalls auf das Dateisystem des ARM zuzugreifen. Eine gleichzeitige Ausführung eines zweiten Programms auf dem ARM ist möglich. Allerdings sind keine Protokolle zur Kommunikation dieser beiden Programme definiert. \textbf{Abbildung \ref{fig:c6app}} verdeutlicht dieses Prinzip.\\ 
%
\begin{figure}[htb]
	\centering
		\includegraphics[scale=1]{../Pictures/c6app.pdf}
	\caption{Prinzip von C6Runapp\cite{c6run}}
	\label{fig:c6app}
\end{figure} 
% 
Die in dieser Arbeit verwendete Version von C6EZRun ist 0.98.

\subsection{Compileroptimierungsstufen}
Da die beiden Compiler aus dem C6EZRun-Framework auf dem C6000-DSP-Compiler aufsetzen, können auch die Compileroptimierungen des C6000-Compilers verwendet werden. Diese Optimierungsstufen zielen auf Geschwindigkeit ab.\\

\subsubsection{Optimierungsstufe \-O0}
In der niedrigsten Optimierungsstufe, welche entweder durch das Compilerflag \textit{\-opt\_level=0} oder \textit{\-O0} aufgerufen wird, werden nur einfache Optimierungen des Codes durchgeführt:

\begin{itemize}
\item Kontrollfluss-Graph-Vereinfachung
\item Allokierung von Variablen auf Register
\item Loop Rotation 
\item Eliminierung von unbenutztem Code
\item Vereinfachung von Ausdrücken und Statements
\item Unterstützung von Inline-Funktionen 
\end{itemize}

\subsubsection{Optimierungsstufe \-O1}

Die nächst höhere Optimierungsstufe wird mit dem Compilerflag  \textit{\-opt\_level=1} oder \textit{\-O1} aufgerufen. Diese Stufe schließt alle Optimierungen der Stufe 0 ein und erweitert diese um folgende:

\begin{itemize}
\item Durchführung von lokalen Kopier- und Konstantenpropagation
\item Entfernung von überflüssigen Anweisungen
\item Lokale Eliminierung von mehrfach verwendeten Ausdrücken
\end{itemize}

\subsubsection{Optimierungsstufe \-O2}

Die Optimierungsstufe 2 wird mit dem Compilerflag \textit{\-opt\_level=2} oder \textit{\-O3} aufgerufen und erweitert die Optimierungsstufe 1 um:

\begin{itemize}
\item Optimierung für Verwendung der Software Pipelined Loop (\textbf{\ref{ph:sploop}})
\item Schleifenoptimierung
\item Eliminierung von globalen verbreiteten Ausdrücken
\item Eliminierung von globalen überflüssigen Ausdrücken
\item Konvertierung von Arrayreferenzen in Schleifen zu Pointerarithmetik
\item Loop Unrolling
\end{itemize}

\subsubsection{Optimierungsstufe \-O3}\label{ph:o3}

Die letzte Optimierungsstufe wird mit \textit{\-opt\_level=3} oder \textit{\-O3} aufgerufen. Auch diese schließt alle Optimierungen der vorherigen Stufen ein. Außerdem kommen folgende dazu:

\begin{itemize}
\item Entfernung von unverwendeten Funktionen
\item Vereinfachung von Funktionen, deren Rückgabewert nie verwendet wird
\item Inline Calls zu kleinen Funktionen
\item Neusortierung von Funktionsdeklarationen
\item Propagierung von Argumenten in den Funktionskörper, wenn alle Aufrufe den selben Wert an der selben Position besitzen
\item Identifizierung von File-Level Charakteristiken von Variablen
\end{itemize}

\section{Libav-Bibliothek}

Die Libav-Bibliothek ist ein unter LGPL lizenziertes Opensource-Projekt, welches Plattform-übergreifende Werkzeuge für die Konvertierung, Manipulation von Audio- und Videoformaten. Diese Bibliothek bietet hierfür eine Vielzahl von Kodierern und Dekodierern, Multimediacodecs und Algorithmen, die für die Benutzung auf verschiedenen Plattformen optimiert sind. Im Spektrum der Achritekturen, für die die Bibliothek optimiert wurde, befinden sich auch ARM-spezifische Architekturen mit NEON-SIMD-Einheiten.